{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.notebook\n",
    "import time\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "plt.style.use('classic')\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#gpytorch.settings.cholesky_max_tries._set_value(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from pydap.client import open_url\n",
    "raw_dataset = open_url('https://dods.ndbc.noaa.gov/thredds/dodsC/data/stdmet/46221/46221h2022.nc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "wave_height = raw_dataset['wave_height'].data[0]\n",
    "time_ = raw_dataset['wave_height'].data[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "             Time  Wave Height\n0      1640996760         2.25\n1      1640998560         2.22\n2      1641000360         2.45\n3      1641002160         2.24\n4      1641003960         2.40\n...           ...          ...\n11640  1661982960         0.92\n11641  1661984760         0.94\n11642  1661986560         1.06\n11643  1661988360         1.11\n11644  1661990160         1.15\n\n[11645 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>Wave Height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1640996760</td>\n      <td>2.25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1640998560</td>\n      <td>2.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1641000360</td>\n      <td>2.45</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1641002160</td>\n      <td>2.24</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1641003960</td>\n      <td>2.40</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11640</th>\n      <td>1661982960</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>11641</th>\n      <td>1661984760</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>11642</th>\n      <td>1661986560</td>\n      <td>1.06</td>\n    </tr>\n    <tr>\n      <th>11643</th>\n      <td>1661988360</td>\n      <td>1.11</td>\n    </tr>\n    <tr>\n      <th>11644</th>\n      <td>1661990160</td>\n      <td>1.15</td>\n    </tr>\n  </tbody>\n</table>\n<p>11645 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave_data = pd.DataFrame(time_, columns = ['Time'])\n",
    "wave_height = np.ravel(wave_height)\n",
    "\n",
    "wave_data['Wave Height'] = wave_height\n",
    "wave_data.set_index('Time')\n",
    "wave_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#wave_data['WVHT'] = wave_data['WVHT'].astype(float)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#wave_data = wave_data.reindex(index=wave_data.index[::-1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "y = torch.tensor(wave_data['Wave Height'].values.astype(np.float32)).cuda()\n",
    "X = torch.tensor(wave_data['Time'].values.astype(np.float32)).cuda()\n",
    "X = X.reshape(-1,1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.6620e+09)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n",
    "# Standardizze\n",
    "X = (X - X.min(0).values) / (X.max(0).values - X.min(0).values) * 100\n",
    "\n",
    "y = y - torch.min(y)\n",
    "y = 2 * (y / torch.max(y)) - 1\n",
    "\n",
    "# Training vs test\n",
    "from math import floor\n",
    "\n",
    "train_n = int(floor(0.7 * len(X)))\n",
    "train_x = X[:train_n].contiguous().cuda()\n",
    "train_y = y[:train_n].contiguous().cuda()\n",
    "\n",
    "test_x = X[train_n:].contiguous().cuda()\n",
    "test_y = y[train_n:].contiguous().cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, generator = torch.Generator(device='cuda'))\n",
    "\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False, generator = torch.Generator(device='cuda'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function for Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "\n",
    "def train_and_test_approximate_gp(model_cls, kernel, num_ind_pts=128, num_epochs=100):\n",
    "    start_time = time.time()\n",
    "    inducing_points = torch.randn(num_ind_pts, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "    model = model_cls(inducing_points, kernel)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.numel())\n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + list(likelihood.parameters()), lr=0.1)\n",
    "    optimizer.param_groups[0]['capturable'] = True\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        likelihood = likelihood.cuda()\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    epochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=f\"Training {model_cls.__name__}\")\n",
    "    for i in epochs_iter:\n",
    "        # Within each iteration, we will go over each minibatch of data\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            epochs_iter.set_postfix(loss=loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    means = torch.tensor([0.]).cuda()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            preds = model(x_batch)\n",
    "            means = torch.cat([means, preds.mean])\n",
    "    means = means[1:]\n",
    "    error = torch.mean(torch.abs(means - test_y))\n",
    "    print(f\"Test {model_cls.__name__} MAE: {error.item()}\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    return model, likelihood\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from gpytorch.kernels import PeriodicKernel\n",
    "from custom_kernel import MinKernel, AR2Kernel, MaternKernel, LinearKernel\n",
    "\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class StandardApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MeanFieldApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.MeanFieldVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MAPApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "def make_orthogonal_vs(model, train_x):\n",
    "    mean_inducing_points = torch.randn(1000, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "    covar_inducing_points = torch.randn(100, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "\n",
    "    covar_variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "        model, covar_inducing_points,\n",
    "        gpytorch.variational.CholeskyVariationalDistribution(covar_inducing_points.size(-2)),\n",
    "        learn_inducing_locations=True\n",
    "    )\n",
    "\n",
    "    variational_strategy = gpytorch.variational.OrthogonallyDecoupledVariationalStrategy(\n",
    "        covar_variational_strategy, mean_inducing_points,\n",
    "        gpytorch.variational.DeltaVariationalDistribution(mean_inducing_points.size(-2)),\n",
    "    )\n",
    "    return variational_strategy\n",
    "\n",
    "class OrthDecoupledApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = make_orthogonal_vs(self, train_x)\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "kernel = (\n",
    "        #ScaleKernel(AR2Kernel()) +\n",
    "        #ScaleKernel(MinKernel()*RBFKernel()) +\n",
    "        ScaleKernel(MinKernel()*MaternKernel())\n",
    "        #ScaleKernel(RBFKernel()) +\n",
    "        #ScaleKernel(RBFKernel()*LinearKernel())+\n",
    "        #ScaleKernel(MaternKernel())+\n",
    "        #ScaleKernel(MaternKernel()*PeriodicKernel())\n",
    "        #ScaleKernel(RBFKernel()*PeriodicKernel())\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Training StandardApproximateGP:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8033c6ca2fc34baaaa081db504623aa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-07 to the diagonal\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NotPSDError",
     "evalue": "Matrix not positive definite after repeatedly adding jitter up to 1.0e-06.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotPSDError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [35]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m num_ind_pts \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;66;03m# Number of inducing points (128 is default for train_and_test_approximate_gp function)\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m m1, l1 \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_test_approximate_gp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mStandardApproximateGP\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_ind_pts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_ind_pts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m m2, l2 \u001B[38;5;241m=\u001B[39m train_and_test_approximate_gp(MeanFieldApproximateGP, kernel, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, num_ind_pts\u001B[38;5;241m=\u001B[39mnum_ind_pts)\n\u001B[0;32m      4\u001B[0m m3, l3 \u001B[38;5;241m=\u001B[39m train_and_test_approximate_gp(MAPApproximateGP, kernel, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, num_ind_pts\u001B[38;5;241m=\u001B[39mnum_ind_pts)\n",
      "Input \u001B[1;32mIn [31]\u001B[0m, in \u001B[0;36mtrain_and_test_approximate_gp\u001B[1;34m(model_cls, kernel, num_ind_pts, num_epochs)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_batch, y_batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     21\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 22\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mmll(output, y_batch)\n\u001B[0;32m     24\u001B[0m     epochs_iter\u001B[38;5;241m.\u001B[39mset_postfix(loss\u001B[38;5;241m=\u001B[39mloss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\models\\approximate_gp.py:108\u001B[0m, in \u001B[0;36mApproximateGP.__call__\u001B[1;34m(self, inputs, prior, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    107\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m--> 108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvariational_strategy(inputs, prior\u001B[38;5;241m=\u001B[39mprior, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py:242\u001B[0m, in \u001B[0;36mVariationalStrategy.__call__\u001B[1;34m(self, x, prior, **kwargs)\u001B[0m\n\u001B[0;32m    239\u001B[0m         \u001B[38;5;66;03m# Mark that we have updated the variational strategy\u001B[39;00m\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdated_strategy\u001B[38;5;241m.\u001B[39mfill_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 242\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(x, prior\u001B[38;5;241m=\u001B[39mprior, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\variational\\_variational_strategy.py:302\u001B[0m, in \u001B[0;36m_VariationalStrategy.__call__\u001B[1;34m(self, x, prior, **kwargs)\u001B[0m\n\u001B[0;32m    300\u001B[0m \u001B[38;5;66;03m# Get q(f)\u001B[39;00m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(variational_dist_u, MultivariateNormal):\n\u001B[1;32m--> 302\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[0;32m    303\u001B[0m         x,\n\u001B[0;32m    304\u001B[0m         inducing_points,\n\u001B[0;32m    305\u001B[0m         inducing_values\u001B[38;5;241m=\u001B[39mvariational_dist_u\u001B[38;5;241m.\u001B[39mmean,\n\u001B[0;32m    306\u001B[0m         variational_inducing_covar\u001B[38;5;241m=\u001B[39mvariational_dist_u\u001B[38;5;241m.\u001B[39mlazy_covariance_matrix,\n\u001B[0;32m    307\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    308\u001B[0m     )\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(variational_dist_u, Delta):\n\u001B[0;32m    310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[0;32m    311\u001B[0m         x, inducing_points, inducing_values\u001B[38;5;241m=\u001B[39mvariational_dist_u\u001B[38;5;241m.\u001B[39mmean, variational_inducing_covar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    312\u001B[0m     )\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\module.py:30\u001B[0m, in \u001B[0;36mModule.__call__\u001B[1;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 30\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(outputs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m     32\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [_validate_module_outputs(output) \u001B[38;5;28;01mfor\u001B[39;00m output \u001B[38;5;129;01min\u001B[39;00m outputs]\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py:176\u001B[0m, in \u001B[0;36mVariationalStrategy.forward\u001B[1;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m data_data_covar \u001B[38;5;241m=\u001B[39m full_covar[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, num_induc:, num_induc:]\n\u001B[0;32m    173\u001B[0m \u001B[38;5;66;03m# Compute interpolation terms\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;66;03m# K_ZZ^{-1/2} K_ZX\u001B[39;00m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;66;03m# K_ZZ^{-1/2} \\mu_Z\u001B[39;00m\n\u001B[1;32m--> 176\u001B[0m L \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cholesky_factor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minduc_induc_covar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m L\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m induc_induc_covar\u001B[38;5;241m.\u001B[39mshape:\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;66;03m# Aggressive caching can cause nasty shape incompatibilies when evaluating with different batch shapes\u001B[39;00m\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;66;03m# TODO: Use a hook fo this\u001B[39;00m\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\utils\\memoize.py:76\u001B[0m, in \u001B[0;36m_cached_ignore_args.<locals>.g\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m cache_name \u001B[38;5;241m=\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m method\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_in_cache_ignore_args(\u001B[38;5;28mself\u001B[39m, cache_name):\n\u001B[1;32m---> 76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _add_to_cache_ignore_args(\u001B[38;5;28mself\u001B[39m, cache_name, method(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _get_from_cache_ignore_args(\u001B[38;5;28mself\u001B[39m, cache_name)\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\variational\\variational_strategy.py:86\u001B[0m, in \u001B[0;36mVariationalStrategy._cholesky_factor\u001B[1;34m(self, induc_induc_covar)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;129m@cached\u001B[39m(name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcholesky_factor\u001B[39m\u001B[38;5;124m\"\u001B[39m, ignore_args\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cholesky_factor\u001B[39m(\u001B[38;5;28mself\u001B[39m, induc_induc_covar):\n\u001B[1;32m---> 86\u001B[0m     L \u001B[38;5;241m=\u001B[39m \u001B[43mpsd_safe_cholesky\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelazify\u001B[49m\u001B[43m(\u001B[49m\u001B[43minduc_induc_covar\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_linalg_dtype_cholesky\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m TriangularLazyTensor(L)\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\utils\\cholesky.py:65\u001B[0m, in \u001B[0;36mpsd_safe_cholesky\u001B[1;34m(A, upper, out, jitter, max_tries)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpsd_safe_cholesky\u001B[39m(A, upper\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, jitter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, max_tries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute the Cholesky decomposition of A. If A is only p.s.d, add a small jitter to the diagonal.\u001B[39;00m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;124;03m        A (Tensor):\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;124;03m            Number of attempts (with successively increasing jitter) to make before raising an error.\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m     L \u001B[38;5;241m=\u001B[39m \u001B[43m_psd_safe_cholesky\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjitter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjitter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_tries\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m upper:\n\u001B[0;32m     67\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\utils\\cholesky.py:47\u001B[0m, in \u001B[0;36m_psd_safe_cholesky\u001B[1;34m(A, out, jitter, max_tries)\u001B[0m\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39many(info):\n\u001B[0;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m L\n\u001B[1;32m---> 47\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m NotPSDError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMatrix not positive definite after repeatedly adding jitter up to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjitter_new\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1e\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNotPSDError\u001B[0m: Matrix not positive definite after repeatedly adding jitter up to 1.0e-06."
     ]
    }
   ],
   "source": [
    "num_ind_pts = 100 # Number of inducing points (128 is default for train_and_test_approximate_gp function)\n",
    "m1, l1 = train_and_test_approximate_gp(StandardApproximateGP, kernel, num_epochs=100, num_ind_pts=num_ind_pts)\n",
    "m2, l2 = train_and_test_approximate_gp(MeanFieldApproximateGP, kernel, num_epochs=100, num_ind_pts=num_ind_pts)\n",
    "m3, l3 = train_and_test_approximate_gp(MAPApproximateGP, kernel, num_epochs=100, num_ind_pts=num_ind_pts)\n",
    "m4, l4 = train_and_test_approximate_gp(OrthDecoupledApproximateGP, kernel, num_epochs=100, num_ind_pts=num_ind_pts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [36]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pairs \u001B[38;5;241m=\u001B[39m [[\u001B[43mm1\u001B[49m, l1], [m2, l2], [m3, l3], [m4, l4]]\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pair \u001B[38;5;129;01min\u001B[39;00m pairs:\n\u001B[0;32m      4\u001B[0m     model \u001B[38;5;241m=\u001B[39m pair[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'm1' is not defined"
     ]
    }
   ],
   "source": [
    "pairs = [[m1, l1], [m2, l2], [m3, l3], [m4, l4]]\n",
    "\n",
    "for pair in pairs:\n",
    "    model = pair[0]\n",
    "    likelihood = pair[1]\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x[:,0].detach().cpu().numpy(),\n",
    "                    lower.detach().cpu().numpy(),\n",
    "                    upper.detach().cpu().numpy(), alpha=0.3)\n",
    "    # Plot training data as black stars\n",
    "    ax.scatter(train_x[:,0].detach().cpu().numpy(), train_y.detach().cpu().numpy(), s=0.5)\n",
    "    #ax.scatter(model.variational_strategy.inducing_points[:,0].detach().cpu().numpy(),\n",
    "    #           np.zeros(500)+1, s=0.5)\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x[:,0].detach().cpu().numpy(), observed_pred.mean.detach().cpu().numpy(), 'blue')\n",
    "    ax.scatter(test_x[:,0].detach().cpu().numpy(),\n",
    "               test_y.detach().cpu().numpy(),\n",
    "               s=1, color=\"red\")\n",
    "\n",
    "    ax.vlines(m1.variational_strategy.inducing_points.detach().cpu().numpy(), ymin = -1.6, ymax = -1.5)\n",
    "\n",
    "\n",
    "    #ax.set_ylim([0, 1.5])\n",
    "    #ax.patch.set_facecolor('green')\n",
    "    #ax.patch.set_alpha(.1)\n",
    "    ax.legend([\"95% Credible Intervals\", \"Observed Data\", \"Posterior Mean\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from gpytorch.kernels import PeriodicKernel\n",
    "from custom_kernel import MinKernel, AR2Kernel\n",
    "\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "kernel = (\n",
    "        #ScaleKernel(AR2Kernel()) +\n",
    "        #ScaleKernel(MinKernel()) +\n",
    "        ScaleKernel(RBFKernel()) +\n",
    "        ScaleKernel(RBFKernel()*PeriodicKernel())\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "class StandardApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MeanFieldApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.MeanFieldVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MAPApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "def make_orthogonal_vs(model, train_x):\n",
    "    mean_inducing_points = torch.randn(1000, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "    covar_inducing_points = torch.randn(100, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "\n",
    "    covar_variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "        model, covar_inducing_points,\n",
    "        gpytorch.variational.CholeskyVariationalDistribution(covar_inducing_points.size(-2)),\n",
    "        learn_inducing_locations=True\n",
    "    )\n",
    "\n",
    "    variational_strategy = gpytorch.variational.OrthogonallyDecoupledVariationalStrategy(\n",
    "        covar_variational_strategy, mean_inducing_points,\n",
    "        gpytorch.variational.DeltaVariationalDistribution(mean_inducing_points.size(-2)),\n",
    "    )\n",
    "    return variational_strategy\n",
    "\n",
    "class OrthDecoupledApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = make_orthogonal_vs(self, train_x)\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Training StandardApproximateGP:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7524e548e4dd4a2fbac7af8675285c08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\MortKernel-gpytorch\\lib\\site-packages\\gpytorch\\lazy\\triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:2189.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test StandardApproximateGP MAE: 0.16866812109947205\n",
      "--- 29.70455527305603 seconds ---\n",
      "Test MeanFieldApproximateGP MAE: 0.17623937129974365\n",
      "--- 28.23924422264099 seconds ---\n",
      "Test MAPApproximateGP MAE: 0.1618404984474182\n",
      "--- 27.39785885810852 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training MeanFieldApproximateGP:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49942c3de3da4c679b2132b0dee86144"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training MAPApproximateGP:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "050ab6409b11401c9667fb85ca8a4ff9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training OrthDecoupledApproximateGP:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f644b9ffef78465ba3921b2087434f4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m1, l1 = train_and_test_approximate_gp(StandardApproximateGP, kernel, num_epochs=100)\n",
    "m2, l2 = train_and_test_approximate_gp(MeanFieldApproximateGP, kernel, num_epochs=100)\n",
    "m3, l3 = train_and_test_approximate_gp(MAPApproximateGP, kernel, num_epochs=100)\n",
    "m4, l4 = train_and_test_approximate_gp(OrthDecoupledApproximateGP, kernel, num_epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairs = [[m1, l1], [m2, l2], [m3, l3], [m4, l4]]\n",
    "\n",
    "for pair in pairs:\n",
    "    model = pair[0]\n",
    "    likelihood = pair[1]\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x[:,0].detach().cpu().numpy(),\n",
    "                    lower.detach().cpu().numpy(),\n",
    "                    upper.detach().cpu().numpy(), alpha=0.3)\n",
    "    # Plot training data as black stars\n",
    "    ax.scatter(train_x[:,0].detach().cpu().numpy(), train_y.detach().cpu().numpy(), s=0.5)\n",
    "    #ax.scatter(model.variational_strategy.inducing_points[:,0].detach().cpu().numpy(),\n",
    "    #           np.zeros(500)+1, s=0.5)\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x[:,0].detach().cpu().numpy(), observed_pred.mean.detach().cpu().numpy(), 'blue')\n",
    "    ax.scatter(test_x[:,0].detach().cpu().numpy(),\n",
    "               test_y.detach().cpu().numpy(),\n",
    "               s=1, color=\"red\")\n",
    "\n",
    "    ax.vlines(m1.variational_strategy.inducing_points.detach().cpu().numpy(), ymin = -1.6, ymax = -1.5)\n",
    "\n",
    "\n",
    "    #ax.set_ylim([0, 1.5])\n",
    "    #ax.patch.set_facecolor('green')\n",
    "    #ax.patch.set_alpha(.1)\n",
    "    ax.legend([\"95% Credible Intervals\", \"Observed Data\", \"Posterior Mean\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}