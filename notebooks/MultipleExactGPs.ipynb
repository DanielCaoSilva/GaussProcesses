{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/dcaos/PycharmProjects/GaussProcesses/notebooks', '/home/dcaos/PycharmProjects/GaussProcesses', '/home/dcaos/anaconda3/lib/python310.zip', '/home/dcaos/anaconda3/lib/python3.10', '/home/dcaos/anaconda3/lib/python3.10/lib-dynload', '', '/home/dcaos/anaconda3/lib/python3.10/site-packages', '/home/dcaos/anaconda3/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-linux-x86_64.egg', '/home/dcaos/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg', '/home/dcaos/PycharmProjects/GaussProcesses']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.notebook\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import glob\n",
    "from skimage.measure import block_reduce\n",
    "import tqdm.notebook\n",
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('classic')\n",
    "\n",
    "import src.utils\n",
    "from src.utils import set_gpytorch_settings\n",
    "# import GPUtil\n",
    "set_gpytorch_settings()\n",
    "# Kernel Imports\n",
    "from gpytorch.kernels import PeriodicKernel\n",
    "from src.custom_kernel import MinKernel, AR2Kernel, MaternKernel, LinearKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.constraints import Interval\n",
    "# from gpytorch.metrics import mean_standardized_log_loss, quantile_coverage_error, mean_squared_error, mean_absolute_error\n",
    "from src.custom_kernel import noise_lower, noise_upper, noise_init"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:31.469574Z",
     "end_time": "2023-04-12T20:04:32.979860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7642349568, 8353546240)\n",
      "Before Block Reduce: (174818, 2)\n",
      "After Block Reduce: (7285, 2)\n",
      "Number of Nans: 0\n",
      "Start Time: 2012-09-30 16:55:44\n",
      "End Time: 2023-02-22 23:25:52\n",
      "Number of Days: 3642.0416666666665\n",
      "Time Period (Days): 3797.312592592593\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(torch.cuda.mem_get_info(device=None))\n",
    "df = pd.read_feather('../Data/feather/46221_9999_wave_height.feather')\n",
    "# df = pd.read_feather('../data/feather/combined/combined_data.feather')\n",
    "parameters_wave = ['time', 'wave_height']\n",
    "parameters_temp = ['time', 'sea_surface_temperature']\n",
    "df_as_np = df \\\n",
    "    .loc[:, parameters_wave] \\\n",
    "    .astype(float) \\\n",
    "    .replace(to_replace = [999.0, 99.0, 9999.0], value = np.nan) \\\n",
    "    .to_numpy()\n",
    "using_sk = block_reduce(df_as_np, block_size=(24,1), func=np.mean).astype(float)\n",
    "plt.plot(using_sk[:-1,0], using_sk[:-1,1])\n",
    "\n",
    "print(f'Before Block Reduce: {df_as_np.shape}\\n'\n",
    "      f'After Block Reduce: {using_sk.shape}\\n'\n",
    "      f'Number of Nans: {np.count_nonzero(np.isnan(df_as_np))}\\n'\n",
    "      f'Start Time: {datetime.fromtimestamp(df_as_np[0,0])}\\n'\n",
    "      f'End Time: {datetime.fromtimestamp(df_as_np[-1,0])}\\n'\n",
    "      f'Number of Days: {df_as_np.shape[0]/48}\\n'\n",
    "      f'Time Period (Days): {(df_as_np[-1,0] - df_as_np[0,0]) / 24 / 60 / 60}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:32.924143Z",
     "end_time": "2023-04-12T20:04:33.432812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = torch.tensor(using_sk[:-1,0]).float().cuda()#.type(torch.double)\n",
    "y = torch.tensor(using_sk[:-1,1]).float().cuda()#.type(torch.double)\n",
    "X = X.reshape(-1,1)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "X = X[~torch.any(y.isnan(), dim=1)]\n",
    "y = y[~torch.any(y.isnan(), dim=1)]\n",
    "y = y.flatten()\n",
    "X_old = X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.111532Z",
     "end_time": "2023-04-12T20:04:34.367440Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.3491e+09],\n        [1.3491e+09],\n        [1.3492e+09],\n        ...,\n        [1.6770e+09],\n        [1.6771e+09],\n        [1.6771e+09]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_old"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.144037Z",
     "end_time": "2023-04-12T20:04:34.367910Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def scaler(a, X_old=X_old, center=True):\n",
    "    if center is True:\n",
    "        a = a - X_old.min(0).values\n",
    "    return a / (X_old.max(0).values - X_old.min(0).values)\n",
    "\n",
    "def descaler(a, X_old=X_old, center=True):\n",
    "    if center is True:\n",
    "        a = a * (X_old.max(0).values - X_old.min(0).values)\n",
    "    return a + X_old.min(0).values\n",
    "X = scaler(X, X_old)\n",
    "y = y.log()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.175152Z",
     "end_time": "2023-04-12T20:04:34.368241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677108352.0 1349069952.0 328038400.0\n"
     ]
    }
   ],
   "source": [
    "# max and min\n",
    "scaler_max = X_old.max(0).values.item()\n",
    "scaler_min = X_old.min(0).values.item()\n",
    "\n",
    "scale_factor = scaler_max - scaler_min\n",
    "print(scaler_max, scaler_min, scale_factor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.217424Z",
     "end_time": "2023-04-12T20:04:34.368439Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "predict_days_out = 14\n",
    "test_n = 2*predict_days_out\n",
    "train_x = X[test_n:].contiguous().cuda()\n",
    "train_y = y[test_n:].contiguous().cuda()\n",
    "test_x = X[-test_n:].contiguous().cuda()\n",
    "test_y = y[-test_n:].contiguous().cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.217492Z",
     "end_time": "2023-04-12T20:04:34.368740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Generate the train_loader and train_dataset\n",
    "train_loader, train_dataset, test_loader, test_dataset = src.utils.create_train_loader_and_dataset(\n",
    "    train_x, train_y, test_x, test_y)\n",
    "data_compact = [train_x, train_y, test_x, test_y, train_loader, train_dataset, test_loader, test_dataset]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.260748Z",
     "end_time": "2023-04-12T20:04:34.368834Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class StandardApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MeanFieldApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.MeanFieldVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MAPApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "def make_orthogonal_vs(model, train_x):\n",
    "    mean_inducing_points = torch.randn(1000, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "    covar_inducing_points = torch.randn(100, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "\n",
    "    covar_variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "        model, covar_inducing_points,\n",
    "        gpytorch.variational.CholeskyVariationalDistribution(covar_inducing_points.size(-2)),\n",
    "        learn_inducing_locations=True\n",
    "    )\n",
    "\n",
    "    variational_strategy = gpytorch.variational.OrthogonallyDecoupledVariationalStrategy(\n",
    "        covar_variational_strategy, mean_inducing_points,\n",
    "        gpytorch.variational.DeltaVariationalDistribution(mean_inducing_points.size(-2)),\n",
    "    )\n",
    "    return variational_strategy\n",
    "\n",
    "class OrthDecoupledApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = make_orthogonal_vs(self, train_x)\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class SpectralDeltaGP(gpytorch.models.ExactGP):\n",
    "    # def __init__(self, train_x, train_y, kernel, num_deltas, noise_init=None):\n",
    "    #     likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(1e-11))\n",
    "    #     likelihood.register_prior(\"noise_prior\", gpytorch.priors.HorseshoePrior(0.1), \"noise\")\n",
    "    #     likelihood.noise = 1e-2\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points)\n",
    "        #variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        #super(SpectralDeltaGP, self).__init__(train_x, train_y, likelihood)\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        #base_covar_module = kernel #gpytorch.kernels.SpectralDeltaKernel(num_dims=train_x.size(-1), num_deltas=num_deltas)\n",
    "        #base_covar_module.initialize_from_data(train_x[0], train_y[0])\n",
    "        self.covar_module = kernel#gpytorch.kernels.ScaleKernel(base_covar_module)\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.260796Z",
     "end_time": "2023-04-12T20:04:34.368919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "RQKernel(\n  (raw_lengthscale_constraint): Positive()\n  (raw_alpha_constraint): Positive()\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def period_print(x):\n",
    "  print(f\"raw: {x}\")\n",
    "  print(f\"seconds: {x * (scale_factor)}\")\n",
    "  print(f\"minutes: {x * (scale_factor) / 60}\")\n",
    "  print(f\"hours: {x * (scale_factor) / 60 / 60 }\")\n",
    "  print(f\"days: {x * (scale_factor) / 60 / 60 / 24}\")\n",
    "  print(f\"weeks: {x * (scale_factor) / 60 / 60 / 24 / 7}\")\n",
    "  print(f\"months: {x * (scale_factor) / 60 / 60 / 24 / 30}\")\n",
    "  print(f\"years: {x * (scale_factor) / 60 / 60 / 24 / 365}\")\n",
    "\n",
    "\n",
    "Mat32 = MaternKernel(nu=1.5)\n",
    "Mat12 = MaternKernel(nu=0.5)\n",
    "Mat52 = MaternKernel(nu=2.5)\n",
    "RBF = RBFKernel()\n",
    "Per_Week = PeriodicKernel(\n",
    "    period_length_constraint=Interval(\n",
    "    # lower_bound=scaler(60*60*24*7, center=False) / 100,\n",
    "    lower_bound=1e-4, upper_bound=1,\n",
    "    # upper_bound=scaler(60*60*24*7, center=False) * 100,\n",
    "    initial_value=scaler(60*60*24*7, center=False))\n",
    ")\n",
    "Per_Month = PeriodicKernel(\n",
    "    period_length_constraint=Interval(\n",
    "    lower_bound=1e-4, upper_bound=1,\n",
    "    # lower_bound=scaler(60*60*24*30, center=False) / 100,\n",
    "    # upper_bound=scaler(60*60*24*30, center=False) * 100,\n",
    "    initial_value=scaler(60*60*24*30, center=False))\n",
    ")\n",
    "Per_Arb = PeriodicKernel()\n",
    "\n",
    "k_1 = [Mat32, Mat12, RBF, Per_Week, Per_Month, Per_Arb]\n",
    "k_2 = [*k_1]\n",
    "k_3 = [*k_1]\n",
    "kernel_dict = {\n",
    "    Mat32: 'Mat32',\n",
    "    Mat12: 'Mat12',  # Very Rough - in continuous time AR(1) process in discrete time\n",
    "    Mat52: 'Mat52', # Matern 5/2 (Default)\n",
    "    RBF: 'RBF',\n",
    "    Per_Week: 'Per_Week',\n",
    "    Per_Month: 'Per_Month',\n",
    "    Per_Arb: 'Per_Arb'}\n",
    "from gpytorch.kernels import RQKernel\n",
    "RQKernel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.260867Z",
     "end_time": "2023-04-12T20:04:34.369150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# period_print((scaler(60*60*24, center=False) * 1).item())\n",
    "# period_print((1e-4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.304061Z",
     "end_time": "2023-04-12T20:04:34.369247Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusRBFxPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9554f21facdc4a0fa8118a215d03dfbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 841.4856567382812 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Arb RBF\n",
      "BIC:  -1815.900146484375\n",
      "Iterations Number:  0\n",
      "Memory Check:  (4116774912, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusRBFxPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46522d43fff34135ad07c3a98ce0a885"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 9269.203125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Week RBF\n",
      "BIC:  -1910.422607421875\n",
      "Iterations Number:  1\n",
      "Memory Check:  (4116185088, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusRBFxPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa5c9818f65543ddb7fb12868d517002"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 24443.84765625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Month RBF\n",
      "BIC:  -2242.749755859375\n",
      "Iterations Number:  2\n",
      "Memory Check:  (4174118912, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat0.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56b0681b15124d0b94942fe6ca6d4362"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 9094.0029296875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Arb Mat0.5\n",
      "BIC:  -1394.1737060546875\n",
      "Iterations Number:  3\n",
      "Memory Check:  (4174708736, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat0.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2395c0f96dbc47aeba552bb50800728b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 16713.28125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 9824.560546875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Week Mat0.5\n",
      "BIC:  -245.5525360107422\n",
      "Iterations Number:  4\n",
      "Memory Check:  (4175364096, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat0.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d13ca8a7b3ee4e8fb08f8384f91391b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 48759.9453125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 30599.193359375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Month Mat0.5\n",
      "BIC:  -449.04034423828125\n",
      "Iterations Number:  5\n",
      "Memory Check:  (4170514432, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat1.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1afbe32a94d54bd985d188553a218df0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 4824901.5 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 384648.5625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 53023.74609375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 286108.59375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 80945.9609375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 86412.6640625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 54635.359375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 117750.421875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 301349.65625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 47851.98828125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 87979.0234375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 194568.828125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 51532.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 184692.421875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 44939.0703125 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Arb Mat1.5\n",
      "BIC:  38114764.0\n",
      "Iterations Number:  6\n",
      "Memory Check:  (4172611584, 8353546240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 71171.90625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat1.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e28732c1e8a40888b7958d547c3e563"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 130767.4453125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 20525.099609375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Week Mat1.5\n",
      "BIC:  421.194580078125\n",
      "Iterations Number:  7\n",
      "Memory Check:  (4172414976, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat1.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b95bdcffa7e43fd94fd44c472865900"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 46575.41796875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 20838.34375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Month Mat1.5\n",
      "BIC:  69.50364685058594\n",
      "Iterations Number:  8\n",
      "Memory Check:  (4172939264, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat2.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "215604903bcb48089b004dbd5fb6a399"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 10129.6123046875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 12859.4970703125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Arb Mat2.5\n",
      "BIC:  -1899.3201904296875\n",
      "Iterations Number:  9\n",
      "Memory Check:  (4172480512, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat2.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c607955522cc43fcb0a38097f5b8cce2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Week Mat2.5\n",
      "BIC:  1511.7332763671875\n",
      "Iterations Number:  10\n",
      "Memory Check:  (4172087296, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPRBFplusMat2.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7815e40791d84f5182dae8a90ec73429"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 49357.26953125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 13609.4716796875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 32198.0625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 2281.970703125 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  RBF Per_Month Mat2.5\n",
      "BIC:  773.9837036132812\n",
      "Iterations Number:  11\n",
      "Memory Check:  (4171563008, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusRBFxPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "511e07fc6a5a43db8c352c9c2a2ba8b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 24021.537109375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Arb RBF\n",
      "BIC:  -1248.6121826171875\n",
      "Iterations Number:  12\n",
      "Memory Check:  (4172152832, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusRBFxPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a10d8710db14ef4bfda86631243e698"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 1939.3125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 9163.9453125 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Week RBF\n",
      "BIC:  4406.75146484375\n",
      "Iterations Number:  13\n",
      "Memory Check:  (4172480512, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusRBFxPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8b9d3c25ed3477eb8870d40a354d472"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 30890.2109375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Month RBF\n",
      "BIC:  -1315.8792724609375\n",
      "Iterations Number:  14\n",
      "Memory Check:  (4172546048, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat0.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cbf34aa70f746e4b3b841c567484048"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Arb Mat0.5\n",
      "BIC:  -2551.083984375\n",
      "Iterations Number:  15\n",
      "Memory Check:  (4173070336, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat0.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14b613be84bb49cd8b85b64ef6531b5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 6633.17919921875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Week Mat0.5\n",
      "BIC:  -1305.764404296875\n",
      "Iterations Number:  16\n",
      "Memory Check:  (4170645504, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat0.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7b64442d98c427e9591965fb610d069"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 24736.404296875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 24288.021484375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 10597.5478515625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Month Mat0.5\n",
      "BIC:  -862.9265747070312\n",
      "Iterations Number:  17\n",
      "Memory Check:  (4170645504, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat1.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b96d9bbe3e1410381188d96488bcdd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 44533.21875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Arb Mat1.5\n",
      "BIC:  -1390.0506591796875\n",
      "Iterations Number:  18\n",
      "Memory Check:  (4170645504, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat1.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfa7f8d50ab14b7d88ff15ec9c68da26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 54723.1796875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Week Mat1.5\n",
      "BIC:  -1284.9490966796875\n",
      "Iterations Number:  19\n",
      "Memory Check:  (4170121216, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat1.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0efe8579fae940b0bcf3b14999fc8ae0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 26033.509765625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 20987.6875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 32945.0234375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 79422.71875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Month Mat1.5\n",
      "BIC:  -57.435325622558594\n",
      "Iterations Number:  20\n",
      "Memory Check:  (4129226752, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat2.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "620bf6edd2394f1ebbf5f51745ab3ab9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 436961.84375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Arb Mat2.5\n",
      "BIC:  -1784.057373046875\n",
      "Iterations Number:  21\n",
      "Memory Check:  (3813801984, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat2.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf0cb7ec29764c47a37a2419db0e41a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 63842.3515625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Week Mat2.5\n",
      "BIC:  -1182.9886474609375\n",
      "Iterations Number:  22\n",
      "Memory Check:  (3800891392, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat0.5plusMat2.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49ae68e236db476686379f8712811e4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 47281.796875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 519622.09375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 39670.5234375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 19814.89453125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 101309.3828125 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat0.5 Per_Month Mat2.5\n",
      "BIC:  -684.656494140625\n",
      "Iterations Number:  23\n",
      "Memory Check:  (3976921088, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusRBFxPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d231e147433d443e97a2be9ac92d5a34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 160896.453125 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Arb RBF\n",
      "BIC:  3008.748291015625\n",
      "Iterations Number:  24\n",
      "Memory Check:  (3929079808, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusRBFxPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33ba7c5b3fce4064b80763360997ea72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 18966.76953125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 13492.5771484375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 3721.78173828125 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Week RBF\n",
      "BIC:  4658.58544921875\n",
      "Iterations Number:  25\n",
      "Memory Check:  (3957325824, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusRBFxPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04e07e36590942bc911fd2b0a3511872"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 248267.078125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 41740.5625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 2753309.75 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Month RBF\n",
      "BIC:  2271.631103515625\n",
      "Iterations Number:  26\n",
      "Memory Check:  (3589210112, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat0.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "325008143bcf4c65a755ab9ec24233a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 24652.650390625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Arb Mat0.5\n",
      "BIC:  -1683.451904296875\n",
      "Iterations Number:  27\n",
      "Memory Check:  (3575185408, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat0.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f0281a947e74144b6f44c1ef65e2245"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 20540.822265625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 43495.19921875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 2533.672607421875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Week Mat0.5\n",
      "BIC:  -358.19317626953125\n",
      "Iterations Number:  28\n",
      "Memory Check:  (3842899968, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat0.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1d10347ecd24ca09b9ccd432ff0ec2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 25498.09765625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 34588.43359375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Month Mat0.5\n",
      "BIC:  -498.749755859375\n",
      "Iterations Number:  29\n",
      "Memory Check:  (3591700480, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat1.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d52a7d0613a5496ea0e349cc1817a6ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 80423.9140625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Arb Mat1.5\n",
      "BIC:  2790.686767578125\n",
      "Iterations Number:  30\n",
      "Memory Check:  (3626631168, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat1.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "591661c21eaa440dbad1cc1e1a4d8f17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 80077.3515625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 23741.306640625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Week Mat1.5\n",
      "BIC:  1937.2269287109375\n",
      "Iterations Number:  31\n",
      "Memory Check:  (3438870528, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat1.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad785f40541845bb8f60fd298389801c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 99477.4921875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 37039.38671875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 26970.16015625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 184361.890625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Month Mat1.5\n",
      "BIC:  1323.915283203125\n",
      "Iterations Number:  32\n",
      "Memory Check:  (3494969344, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat2.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86eb2634666d47938a4bd44a3832db32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 297267.65625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Arb Mat2.5\n",
      "BIC:  2597.76123046875\n",
      "Iterations Number:  33\n",
      "Memory Check:  (3407347712, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat2.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "507c910a42c14bd9a12e6492e7971d22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 110715.4375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 91545.0703125 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Week Mat2.5\n",
      "BIC:  1588.5335693359375\n",
      "Iterations Number:  34\n",
      "Memory Check:  (3405316096, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat1.5plusMat2.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b0afb5360ea4fbcb4ac8a933daf0fea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 48927.1875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 99365.6640625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 199744.84375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 37040.359375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 71616.828125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 50364.05078125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 558603.1875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 33227.984375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat1.5 Per_Month Mat2.5\n",
      "BIC:  1277.1741943359375\n",
      "Iterations Number:  35\n",
      "Memory Check:  (3374448640, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusRBFxPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e1db66b713241b2acf628275e0145de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Arb RBF\n",
      "BIC:  450.315673828125\n",
      "Iterations Number:  36\n",
      "Memory Check:  (3356098560, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusRBFxPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be1105c03ead4b529122ca7d62afbbcc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 20873.123046875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Week RBF\n",
      "BIC:  374.224365234375\n",
      "Iterations Number:  37\n",
      "Memory Check:  (3434872832, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusRBFxPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f2adc634b5a4aa3be36ed33712be6e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 36263.59375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 92126.6640625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Month RBF\n",
      "BIC:  1067.511962890625\n",
      "Iterations Number:  38\n",
      "Memory Check:  (3376218112, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat0.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b56861485ac4f8987d1ac50ef34e320"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 18308.353515625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Arb Mat0.5\n",
      "BIC:  -1221.6102294921875\n",
      "Iterations Number:  39\n",
      "Memory Check:  (3375759360, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat0.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "870082720ebe44709e35bba49679d129"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 32310.099609375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 20072.943359375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 16849.37890625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 16251.724609375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 195128.46875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Week Mat0.5\n",
      "BIC:  -579.552490234375\n",
      "Iterations Number:  40\n",
      "Memory Check:  (3318743040, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat0.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "320cb9dc9cd549dab8668da2ff854e5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 70604.546875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 34711.37109375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 51967.1328125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 27824.12890625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 12600.849609375 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Month Mat0.5\n",
      "BIC:  -278.22442626953125\n",
      "Iterations Number:  41\n",
      "Memory Check:  (3314221056, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat1.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a212bec71e1d44e8aba831435bae9297"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 411795.1875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 100628.0625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 1121543.625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Arb Mat1.5\n",
      "BIC:  1644.164306640625\n",
      "Iterations Number:  42\n",
      "Memory Check:  (3257204736, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat1.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20bcb79846f54315809d4fb9c9f7d740"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 28352.154296875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 380144.40625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Week Mat1.5\n",
      "BIC:  819.5017700195312\n",
      "Iterations Number:  43\n",
      "Memory Check:  (3188326400, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat1.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fe92976e9154a8c95f072616449deb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 38152.0703125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 32231.486328125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 60227.359375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 5000.23779296875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Month Mat1.5\n",
      "BIC:  594.460205078125\n",
      "Iterations Number:  44\n",
      "Memory Check:  (3106734080, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat2.5xPer_Arb_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc37105de1e94673ad2c962051d6cfa0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 2271.7919921875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Arb Mat2.5\n",
      "BIC:  -2012.3992919921875\n",
      "Iterations Number:  45\n",
      "Memory Check:  (3113746432, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat2.5xPer_Week_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "439d311675b84156b225a4409a0b3859"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 323038.90625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 44224.29296875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 1397054.625 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Week Mat2.5\n",
      "BIC:  1093.0355224609375\n",
      "Iterations Number:  46\n",
      "Memory Check:  (3118792704, 8353546240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training_exactGPMat2.5plusMat2.5xPer_Month_exact_gp:   0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a84cae395654d538be62da8249788ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 91560.7734375 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 34201.0625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 63016.8125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/dcaos/anaconda3/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:323: NumericalWarning: CG terminated in 1000 iterations with average residual norm 7424.96875 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Structure:  Mat2.5 Per_Month Mat2.5\n",
      "BIC:  1539.3577880859375\n",
      "Iterations Number:  47\n",
      "Memory Check:  (3000696832, 8353546240)\n"
     ]
    }
   ],
   "source": [
    "## Kernel Experimentation for periodicity\n",
    "# kernel = ScaleKernel(PeriodicKernel()) +ScaleKernel(PeriodicKernel()*RBFKernel())  + ScaleKernel(PeriodicKernel()*RBFKernel()) + ScaleKernel(PeriodicKernel()*RBFKernel())\n",
    "def make_kernel(name_of_kernel):\n",
    "    if name_of_kernel == 'RBF':\n",
    "        return RBFKernel()\n",
    "    elif name_of_kernel.startswith('Mat'):\n",
    "        nu_value = float(name_of_kernel[-3:])\n",
    "        return MaternKernel(nu=nu_value)\n",
    "    if name_of_kernel.startswith('Per'):\n",
    "        if name_of_kernel == 'Per_Arb':\n",
    "            return PeriodicKernel()\n",
    "        elif name_of_kernel == 'Per_Week':\n",
    "            return PeriodicKernel(\n",
    "                period_length_constraint=Interval(\n",
    "                lower_bound=1e-4, upper_bound=1,\n",
    "                initial_value=scaler(60*60*24*7, center=False)))\n",
    "        elif name_of_kernel == 'Per_Month':\n",
    "            return PeriodicKernel(\n",
    "                period_length_constraint=Interval(\n",
    "                lower_bound=1e-4, upper_bound=1,\n",
    "                initial_value=scaler(60*60*24*30, center=False)))\n",
    "    else:\n",
    "        raise ValueError('Kernel not found')\n",
    "\n",
    "# kernel = ScaleKernel(RBFKernel()) + ScaleKernel(Per_Month * RBFKernel())\n",
    "# kernel_0 = ScaleKernel(RBFKernel()) + ScaleKernel(Per_Week * RBFKernel())\n",
    "# kernel_1 = ScaleKernel(MaternKernel(nu=2.5)) + ScaleKernel(PeriodicKernel() * RBFKernel())\n",
    "# kernel_2 = ScaleKernel(MaternKernel(nu=1.5)) + ScaleKernel(PeriodicKernel() * RBFKernel())\n",
    "# kernel_3 = ScaleKernel(MaternKernel(nu=0.5)) + ScaleKernel(PeriodicKernel() * RBFKernel())\n",
    "\n",
    "smooth_kernel_list_1 = ['RBF', 'Mat0.5', 'Mat1.5', 'Mat2.5']\n",
    "smooth_kernel_list_2 = ['RBF', 'Mat0.5', 'Mat1.5', 'Mat2.5']\n",
    "periodic_kernel_list = ['Per_Arb', 'Per_Week', 'Per_Month']\n",
    "\n",
    "bic_save = []\n",
    "index_checker = 0\n",
    "# try:\n",
    "for sk1 in smooth_kernel_list_1:\n",
    "    for sk2 in smooth_kernel_list_2:\n",
    "        for pk in periodic_kernel_list:\n",
    "            kernel = ScaleKernel(make_kernel(sk1)) + ScaleKernel(make_kernel(pk) * make_kernel(sk2))\n",
    "            name_of_kernel = f'{sk1}plus{sk2}x{pk}_exact_gp'\n",
    "            k_list = [str(sk1), str(pk), str(sk2)]\n",
    "            exact_gp = src.utils.TrainTestPlotSaveExactGP(\n",
    "                ExactGPModel, kernel,\n",
    "                train_x, train_y, test_x, test_y,\n",
    "                num_iter=1000, lr=0.0063,\n",
    "                name=name_of_kernel)\n",
    "            exact_gp.test_eval_exact_gp()\n",
    "            # exact_gp.plot(show_plot=False)\n",
    "            bic_value = exact_gp.get_BIC()\n",
    "            bic_save.append([\n",
    "                *k_list,\n",
    "                bic_value.item(),\n",
    "                kernel.kernels[0].base_kernel.lengthscale.item(),\n",
    "                kernel.kernels[1].base_kernel.kernels[1].lengthscale.item(),\n",
    "                kernel.kernels[1].base_kernel.kernels[0].lengthscale.item(),\n",
    "                kernel.kernels[1].base_kernel.kernels[0].period_length.item()])\n",
    "            print(\"Kernel Structure: \", *k_list)\n",
    "            print(\"BIC: \", exact_gp.get_BIC().item())\n",
    "            print(\"Iterations Number: \",index_checker)\n",
    "            print(\"Memory Check: \", torch.cuda.mem_get_info(device=None))\n",
    "            index_checker += 1\n",
    "            del exact_gp\n",
    "            del kernel\n",
    "            gc.enable()\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "bic_out_df = pd.DataFrame(bic_save, columns=['add_scale1_K1', 'scale2_mult_K2', 'scale2_mult_K3', 'BIC', 's1_ls', 's2_ls', 'pk_ls', 'pk_pr'])\n",
    "bic_out_df.to_csv('bic_save_linear_kernel_struct.csv')\n",
    "# except:\n",
    "#     print(\"Error\")\n",
    "#     pd.DataFrame(bic_save, columns=['Name', 'BIC', 'Full Kernel', 'Period']).to_csv('bic_save.csv')\n",
    "\n",
    "            # GPUtil.showUtilization(all=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T20:04:33.304126Z",
     "end_time": "2023-04-12T22:30:32.803275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# bic_out_df = pd.DataFrame(bic_save, columns=['Name1', 'Name2', 'Name3', 'BIC', 's1_ls', 's2_ls', 'pk_ls', 'pk_pr'])\n",
    "# bic_out_df.to_csv('bic_save_2.csv')\n",
    "# bic_out_df['BIC'].min()\n",
    "# def period_print(x):\n",
    "#   print(f\"raw: {x}\")\n",
    "#   print(f\"seconds: {x * (scale_factor)}\")\n",
    "#   print(f\"minutes: {x * (scale_factor) / 60}\")\n",
    "#   print(f\"hours: {x * (scale_factor) / 60 / 60 }\")\n",
    "#   print(f\"days: {x * (scale_factor) / 60 / 60 / 24}\")\n",
    "#   print(f\"weeks: {x * (scale_factor) / 60 / 60 / 24 / 7}\")\n",
    "#   print(f\"months: {x * (scale_factor) / 60 / 60 / 24 / 30}\")\n",
    "#   print(f\"years: {x * (scale_factor) / 60 / 60 / 24 / 365}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:30:32.772955Z",
     "end_time": "2023-04-12T22:30:33.004640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   add_scale1_K1 scale2_mult_K2 scale2_mult_K3          BIC     s1_ls  \\\n0            RBF        Per_Arb            RBF -1805.135620  2.833134   \n1            RBF       Per_Week            RBF -1827.237061  0.000386   \n2            RBF      Per_Month            RBF -2233.627686  0.000293   \n3            RBF        Per_Arb         Mat0.5 -1298.525146  1.319847   \n4            RBF       Per_Week         Mat0.5  -322.171631  1.600245   \n5            RBF      Per_Month         Mat0.5  -392.073547  1.264017   \n6            RBF        Per_Arb         Mat1.5  1953.407471  1.762203   \n7            RBF       Per_Week         Mat1.5   509.828369  1.546903   \n8            RBF      Per_Month         Mat1.5    47.187729  1.462433   \n9            RBF        Per_Arb         Mat2.5 -1908.702881  3.312636   \n10           RBF       Per_Week         Mat2.5  1500.211792  1.908295   \n11           RBF      Per_Month         Mat2.5   698.042236  1.363454   \n12        Mat0.5        Per_Arb            RBF -1713.608154  0.033583   \n13        Mat0.5       Per_Week            RBF  4416.419922  0.485157   \n14        Mat0.5      Per_Month            RBF -1367.811768  0.035386   \n15        Mat0.5        Per_Arb         Mat0.5 -2421.545898  0.060981   \n16        Mat0.5       Per_Week         Mat0.5 -1307.643433  0.030418   \n17        Mat0.5      Per_Month         Mat0.5  -757.242493  0.128312   \n18        Mat0.5        Per_Arb         Mat1.5 -1364.527100  0.033105   \n19        Mat0.5       Per_Week         Mat1.5 -1322.005127  0.030787   \n20        Mat0.5      Per_Month         Mat1.5  -296.835205  0.036069   \n21        Mat0.5        Per_Arb         Mat2.5 -1798.739136  0.037739   \n22        Mat0.5       Per_Week         Mat2.5 -1238.739502  0.031497   \n23        Mat0.5      Per_Month         Mat2.5  -707.888000  0.034090   \n24        Mat1.5        Per_Arb            RBF  3010.300049  0.010082   \n25        Mat1.5       Per_Week            RBF  4672.148926  0.141076   \n26        Mat1.5      Per_Month            RBF  2490.795166  0.010138   \n27        Mat1.5        Per_Arb         Mat0.5 -1734.705811  0.798240   \n28        Mat1.5       Per_Week         Mat0.5  -250.053970  0.593730   \n29        Mat1.5      Per_Month         Mat0.5  -516.528564  0.602008   \n30        Mat1.5        Per_Arb         Mat1.5  2968.091064  0.010042   \n31        Mat1.5       Per_Week         Mat1.5  1809.703369  0.010104   \n32        Mat1.5      Per_Month         Mat1.5  1427.461792  0.011544   \n33        Mat1.5        Per_Arb         Mat2.5  2527.500244  0.010075   \n34        Mat1.5       Per_Week         Mat2.5  1960.806396  0.010154   \n35        Mat1.5      Per_Month         Mat2.5  1303.167358  0.010878   \n36        Mat2.5        Per_Arb            RBF   395.543213  0.025056   \n37        Mat2.5       Per_Week            RBF   368.221436  0.025101   \n38        Mat2.5      Per_Month            RBF  1037.097900  0.025749   \n39        Mat2.5        Per_Arb         Mat0.5 -1398.571167  0.831241   \n40        Mat2.5       Per_Week         Mat0.5  -489.410400  0.473279   \n41        Mat2.5      Per_Month         Mat0.5  -402.086670  0.555153   \n42        Mat2.5        Per_Arb         Mat1.5  1129.827026  1.262705   \n43        Mat2.5       Per_Week         Mat1.5  1119.735596  0.025515   \n44        Mat2.5      Per_Month         Mat1.5   699.712646  0.027418   \n45        Mat2.5        Per_Arb         Mat2.5 -2027.209717  3.682471   \n46        Mat2.5       Per_Week         Mat2.5  1056.807861  0.025120   \n47        Mat2.5      Per_Month         Mat2.5  1630.341187  0.025781   \n\n       s2_ls     pk_ls     pk_pr  \n0   0.087118  0.000075  0.220226  \n1   2.457447  2.792247  0.001583  \n2   0.254716  2.288955  0.008738  \n3   0.032006  1.491903  1.482382  \n4   0.057973  4.177843  0.002056  \n5   0.058467  0.198392  0.011295  \n6   0.010063  0.102558  0.073804  \n7   0.011549  4.772974  0.002417  \n8   0.016194  0.226457  0.008751  \n9   0.032085  0.000478  0.109313  \n10  0.028125  4.930425  0.001974  \n11  0.028307  0.358978  0.009358  \n12  1.009137  1.117978  1.158434  \n13  1.057406  0.475433  0.001918  \n14  1.203233  1.572044  0.008661  \n15  0.084893  1.438037  1.436634  \n16  1.320009  2.859185  0.002437  \n17  0.049358  0.419422  0.007621  \n18  0.630001  1.355961  1.324378  \n19  1.538649  2.345045  0.001916  \n20  0.015872  0.673845  0.004960  \n21  0.743992  1.501362  1.435231  \n22  1.025941  2.406729  0.001757  \n23  0.032117  0.180048  0.008471  \n24  1.007719  1.121241  1.078166  \n25  1.004241  0.389434  0.001729  \n26  0.023956  0.206529  0.005714  \n27  0.027663  1.573423  1.561024  \n28  0.055094  4.481592  0.001582  \n29  0.049189  0.484925  0.007929  \n30  0.455721  1.278376  1.316229  \n31  0.033570  3.117956  0.001498  \n32  0.020217  0.327095  0.006561  \n33  0.496206  1.158895  1.194718  \n34  0.032453  3.113066  0.002526  \n35  0.033379  0.271235  0.006387  \n36  1.229306  1.559705  1.235355  \n37  1.037601  0.697538  0.002680  \n38  0.006820  0.180380  0.008831  \n39  0.025352  1.574531  1.564166  \n40  0.034579  5.193639  0.001907  \n41  0.044332  0.343048  0.007536  \n42  0.010068  0.106592  0.068989  \n43  0.013156  3.987653  0.003402  \n44  0.015048  0.804578  0.005754  \n45  0.034286  0.000471  0.081039  \n46  0.030425  3.534079  0.002221  \n47  0.030966  0.506552  0.005128  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>add_scale1_K1</th>\n      <th>scale2_mult_K2</th>\n      <th>scale2_mult_K3</th>\n      <th>BIC</th>\n      <th>s1_ls</th>\n      <th>s2_ls</th>\n      <th>pk_ls</th>\n      <th>pk_pr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>-1805.135620</td>\n      <td>2.833134</td>\n      <td>0.087118</td>\n      <td>0.000075</td>\n      <td>0.220226</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>-1827.237061</td>\n      <td>0.000386</td>\n      <td>2.457447</td>\n      <td>2.792247</td>\n      <td>0.001583</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>-2233.627686</td>\n      <td>0.000293</td>\n      <td>0.254716</td>\n      <td>2.288955</td>\n      <td>0.008738</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-1298.525146</td>\n      <td>1.319847</td>\n      <td>0.032006</td>\n      <td>1.491903</td>\n      <td>1.482382</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-322.171631</td>\n      <td>1.600245</td>\n      <td>0.057973</td>\n      <td>4.177843</td>\n      <td>0.002056</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-392.073547</td>\n      <td>1.264017</td>\n      <td>0.058467</td>\n      <td>0.198392</td>\n      <td>0.011295</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>1953.407471</td>\n      <td>1.762203</td>\n      <td>0.010063</td>\n      <td>0.102558</td>\n      <td>0.073804</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>509.828369</td>\n      <td>1.546903</td>\n      <td>0.011549</td>\n      <td>4.772974</td>\n      <td>0.002417</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>47.187729</td>\n      <td>1.462433</td>\n      <td>0.016194</td>\n      <td>0.226457</td>\n      <td>0.008751</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>-1908.702881</td>\n      <td>3.312636</td>\n      <td>0.032085</td>\n      <td>0.000478</td>\n      <td>0.109313</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>1500.211792</td>\n      <td>1.908295</td>\n      <td>0.028125</td>\n      <td>4.930425</td>\n      <td>0.001974</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>698.042236</td>\n      <td>1.363454</td>\n      <td>0.028307</td>\n      <td>0.358978</td>\n      <td>0.009358</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>-1713.608154</td>\n      <td>0.033583</td>\n      <td>1.009137</td>\n      <td>1.117978</td>\n      <td>1.158434</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>4416.419922</td>\n      <td>0.485157</td>\n      <td>1.057406</td>\n      <td>0.475433</td>\n      <td>0.001918</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>-1367.811768</td>\n      <td>0.035386</td>\n      <td>1.203233</td>\n      <td>1.572044</td>\n      <td>0.008661</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-2421.545898</td>\n      <td>0.060981</td>\n      <td>0.084893</td>\n      <td>1.438037</td>\n      <td>1.436634</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-1307.643433</td>\n      <td>0.030418</td>\n      <td>1.320009</td>\n      <td>2.859185</td>\n      <td>0.002437</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-757.242493</td>\n      <td>0.128312</td>\n      <td>0.049358</td>\n      <td>0.419422</td>\n      <td>0.007621</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>-1364.527100</td>\n      <td>0.033105</td>\n      <td>0.630001</td>\n      <td>1.355961</td>\n      <td>1.324378</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>-1322.005127</td>\n      <td>0.030787</td>\n      <td>1.538649</td>\n      <td>2.345045</td>\n      <td>0.001916</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>-296.835205</td>\n      <td>0.036069</td>\n      <td>0.015872</td>\n      <td>0.673845</td>\n      <td>0.004960</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>-1798.739136</td>\n      <td>0.037739</td>\n      <td>0.743992</td>\n      <td>1.501362</td>\n      <td>1.435231</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>-1238.739502</td>\n      <td>0.031497</td>\n      <td>1.025941</td>\n      <td>2.406729</td>\n      <td>0.001757</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>-707.888000</td>\n      <td>0.034090</td>\n      <td>0.032117</td>\n      <td>0.180048</td>\n      <td>0.008471</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>3010.300049</td>\n      <td>0.010082</td>\n      <td>1.007719</td>\n      <td>1.121241</td>\n      <td>1.078166</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>4672.148926</td>\n      <td>0.141076</td>\n      <td>1.004241</td>\n      <td>0.389434</td>\n      <td>0.001729</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>2490.795166</td>\n      <td>0.010138</td>\n      <td>0.023956</td>\n      <td>0.206529</td>\n      <td>0.005714</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-1734.705811</td>\n      <td>0.798240</td>\n      <td>0.027663</td>\n      <td>1.573423</td>\n      <td>1.561024</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-250.053970</td>\n      <td>0.593730</td>\n      <td>0.055094</td>\n      <td>4.481592</td>\n      <td>0.001582</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-516.528564</td>\n      <td>0.602008</td>\n      <td>0.049189</td>\n      <td>0.484925</td>\n      <td>0.007929</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>2968.091064</td>\n      <td>0.010042</td>\n      <td>0.455721</td>\n      <td>1.278376</td>\n      <td>1.316229</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>1809.703369</td>\n      <td>0.010104</td>\n      <td>0.033570</td>\n      <td>3.117956</td>\n      <td>0.001498</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>1427.461792</td>\n      <td>0.011544</td>\n      <td>0.020217</td>\n      <td>0.327095</td>\n      <td>0.006561</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>2527.500244</td>\n      <td>0.010075</td>\n      <td>0.496206</td>\n      <td>1.158895</td>\n      <td>1.194718</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>1960.806396</td>\n      <td>0.010154</td>\n      <td>0.032453</td>\n      <td>3.113066</td>\n      <td>0.002526</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>1303.167358</td>\n      <td>0.010878</td>\n      <td>0.033379</td>\n      <td>0.271235</td>\n      <td>0.006387</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>395.543213</td>\n      <td>0.025056</td>\n      <td>1.229306</td>\n      <td>1.559705</td>\n      <td>1.235355</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>368.221436</td>\n      <td>0.025101</td>\n      <td>1.037601</td>\n      <td>0.697538</td>\n      <td>0.002680</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>1037.097900</td>\n      <td>0.025749</td>\n      <td>0.006820</td>\n      <td>0.180380</td>\n      <td>0.008831</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-1398.571167</td>\n      <td>0.831241</td>\n      <td>0.025352</td>\n      <td>1.574531</td>\n      <td>1.564166</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-489.410400</td>\n      <td>0.473279</td>\n      <td>0.034579</td>\n      <td>5.193639</td>\n      <td>0.001907</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-402.086670</td>\n      <td>0.555153</td>\n      <td>0.044332</td>\n      <td>0.343048</td>\n      <td>0.007536</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>1129.827026</td>\n      <td>1.262705</td>\n      <td>0.010068</td>\n      <td>0.106592</td>\n      <td>0.068989</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>1119.735596</td>\n      <td>0.025515</td>\n      <td>0.013156</td>\n      <td>3.987653</td>\n      <td>0.003402</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>699.712646</td>\n      <td>0.027418</td>\n      <td>0.015048</td>\n      <td>0.804578</td>\n      <td>0.005754</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>-2027.209717</td>\n      <td>3.682471</td>\n      <td>0.034286</td>\n      <td>0.000471</td>\n      <td>0.081039</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>1056.807861</td>\n      <td>0.025120</td>\n      <td>0.030425</td>\n      <td>3.534079</td>\n      <td>0.002221</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>1630.341187</td>\n      <td>0.025781</td>\n      <td>0.030966</td>\n      <td>0.506552</td>\n      <td>0.005128</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic_out_df\n",
    "# print(bic_save)\n",
    "# for i in bic_save:\n",
    "#     period_print(i[-1].item(), \"\\n------------------\")\n",
    "# kernel.kernels[-1].base_kernel.kernels[0].period_length\n",
    "# period_print(scaler(60*60*24, center=False).item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:30:32.813244Z",
     "end_time": "2023-04-12T22:30:33.037935Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   Kernel  \\\n0           Scale(RBF)+Scale(Per_Arb*RBF)   \n1          Scale(RBF)+Scale(Per_Week*RBF)   \n2         Scale(RBF)+Scale(Per_Month*RBF)   \n3        Scale(RBF)+Scale(Per_Arb*Mat0.5)   \n4       Scale(RBF)+Scale(Per_Week*Mat0.5)   \n5      Scale(RBF)+Scale(Per_Month*Mat0.5)   \n6        Scale(RBF)+Scale(Per_Arb*Mat1.5)   \n7       Scale(RBF)+Scale(Per_Week*Mat1.5)   \n8      Scale(RBF)+Scale(Per_Month*Mat1.5)   \n9        Scale(RBF)+Scale(Per_Arb*Mat2.5)   \n10      Scale(RBF)+Scale(Per_Week*Mat2.5)   \n11     Scale(RBF)+Scale(Per_Month*Mat2.5)   \n12       Scale(Mat0.5)+Scale(Per_Arb*RBF)   \n13      Scale(Mat0.5)+Scale(Per_Week*RBF)   \n14     Scale(Mat0.5)+Scale(Per_Month*RBF)   \n15    Scale(Mat0.5)+Scale(Per_Arb*Mat0.5)   \n16   Scale(Mat0.5)+Scale(Per_Week*Mat0.5)   \n17  Scale(Mat0.5)+Scale(Per_Month*Mat0.5)   \n18    Scale(Mat0.5)+Scale(Per_Arb*Mat1.5)   \n19   Scale(Mat0.5)+Scale(Per_Week*Mat1.5)   \n20  Scale(Mat0.5)+Scale(Per_Month*Mat1.5)   \n21    Scale(Mat0.5)+Scale(Per_Arb*Mat2.5)   \n22   Scale(Mat0.5)+Scale(Per_Week*Mat2.5)   \n23  Scale(Mat0.5)+Scale(Per_Month*Mat2.5)   \n24       Scale(Mat1.5)+Scale(Per_Arb*RBF)   \n25      Scale(Mat1.5)+Scale(Per_Week*RBF)   \n26     Scale(Mat1.5)+Scale(Per_Month*RBF)   \n27    Scale(Mat1.5)+Scale(Per_Arb*Mat0.5)   \n28   Scale(Mat1.5)+Scale(Per_Week*Mat0.5)   \n29  Scale(Mat1.5)+Scale(Per_Month*Mat0.5)   \n30    Scale(Mat1.5)+Scale(Per_Arb*Mat1.5)   \n31   Scale(Mat1.5)+Scale(Per_Week*Mat1.5)   \n32  Scale(Mat1.5)+Scale(Per_Month*Mat1.5)   \n33    Scale(Mat1.5)+Scale(Per_Arb*Mat2.5)   \n34   Scale(Mat1.5)+Scale(Per_Week*Mat2.5)   \n35  Scale(Mat1.5)+Scale(Per_Month*Mat2.5)   \n36       Scale(Mat2.5)+Scale(Per_Arb*RBF)   \n37      Scale(Mat2.5)+Scale(Per_Week*RBF)   \n38     Scale(Mat2.5)+Scale(Per_Month*RBF)   \n39    Scale(Mat2.5)+Scale(Per_Arb*Mat0.5)   \n40   Scale(Mat2.5)+Scale(Per_Week*Mat0.5)   \n41  Scale(Mat2.5)+Scale(Per_Month*Mat0.5)   \n42    Scale(Mat2.5)+Scale(Per_Arb*Mat1.5)   \n43   Scale(Mat2.5)+Scale(Per_Week*Mat1.5)   \n44  Scale(Mat2.5)+Scale(Per_Month*Mat1.5)   \n45    Scale(Mat2.5)+Scale(Per_Arb*Mat2.5)   \n46   Scale(Mat2.5)+Scale(Per_Week*Mat2.5)   \n47  Scale(Mat2.5)+Scale(Per_Month*Mat2.5)   \n\n    Length_Scale_for_smoothing_term_1 (Days)  \\\n0                               10756.675944   \n1                                   1.464003   \n2                                   1.112530   \n3                                5011.118188   \n4                                6075.714930   \n5                                4799.144787   \n6                                6690.627841   \n7                                5873.190601   \n8                                5552.480236   \n9                               12577.218770   \n10                               7245.301506   \n11                               5176.679932   \n12                                127.506101   \n13                               1842.015284   \n14                                134.351948   \n15                                231.530807   \n16                                115.490693   \n17                                487.166801   \n18                                125.690511   \n19                                116.888837   \n20                                136.946248   \n21                                143.284935   \n22                                119.586275   \n23                                129.431518   \n24                                 38.277354   \n25                                535.629953   \n26                                 38.492639   \n27                               3030.710125   \n28                               2254.237419   \n29                               2285.668017   \n30                                 38.126844   \n31                                 38.362508   \n32                                 43.828261   \n33                                 38.252934   \n34                                 38.550601   \n35                                 41.299257   \n36                                 95.132886   \n37                                 95.302267   \n38                                 97.761909   \n39                               3156.005256   \n40                               1796.917545   \n41                               2107.770475   \n42                               4794.162492   \n43                                 96.875436   \n44                                104.099146   \n45                              13981.388718   \n46                                 95.375363   \n47                                 97.883186   \n\n    Length_Scale_for_smoothing_term_2 (Days)  \\\n0                                 330.764572   \n1                                9330.289341   \n2                                 967.088725   \n3                                 121.518015   \n4                                 220.108936   \n5                                 221.984807   \n6                                  38.207175   \n7                                  43.846995   \n8                                  61.485172   \n9                                 121.817838   \n10                                106.783981   \n11                                107.474327   \n12                               3831.431239   \n13                               4014.698055   \n14                               4568.363313   \n15                                322.315168   \n16                               5011.731922   \n17                                187.401082   \n18                               2391.950722   \n19                               5841.851203   \n20                                 60.261670   \n21                               2824.744853   \n22                               3895.232499   \n23                                121.941032   \n24                               3826.049292   \n25                               3812.843584   \n26                                 90.954760   \n27                                105.029607   \n28                                209.177959   \n29                                186.759314   \n30                               1730.256263   \n31                                127.457856   \n32                                 76.758763   \n33                               1883.964350   \n34                                123.214993   \n35                                126.730206   \n36                               4667.357917   \n37                               3939.503777   \n38                                 25.893531   \n39                                 96.256447   \n40                                131.287150   \n41                                168.318785   \n42                                 38.224954   \n43                                 49.950984   \n44                                 57.131838   \n45                                130.175972   \n46                                115.516166   \n47                                117.569770   \n\n    Length_Scale_for_periodic_term_2 (Days)  \\\n0                                  0.285057   \n1                              10601.436349   \n2                               8690.569506   \n3                               5664.370060   \n4                              15862.187083   \n5                                753.243117   \n6                                389.385691   \n7                              18121.744895   \n8                                859.797272   \n9                                  1.816306   \n10                             18719.544291   \n11                              1362.947994   \n12                              4244.671627   \n13                              1805.097394   \n14                              5968.643105   \n15                              5459.851998   \n16                             10855.584100   \n17                              1592.437050   \n18                              5148.232692   \n19                              8903.529136   \n20                              2558.416096   \n21                              5700.281691   \n22                              9137.726887   \n23                               683.594912   \n24                              4257.063095   \n25                              1478.579631   \n26                               784.138790   \n27                              5973.878408   \n28                             17015.443607   \n29                              1841.134398   \n30                              4853.661272   \n31                             11838.071186   \n32                              1241.894807   \n33                              4400.024826   \n34                             11819.505257   \n35                              1029.807123   \n36                              5921.794231   \n37                              2648.371465   \n38                               684.856723   \n39                              5978.086293   \n40                             19718.900031   \n41                              1302.464115   \n42                               404.703036   \n43                             15140.084670   \n44                              3054.774322   \n45                                 1.786906   \n46                             13417.980194   \n47                              1923.247901   \n\n    Period_Length_for_periodic_term_2 (Days) add_scale1_K1 scale2_mult_K2  \\\n0                                 836.139177           RBF        Per_Arb   \n1                                   6.010267           RBF       Per_Week   \n2                                  33.176087           RBF      Per_Month   \n3                                5628.218547           RBF        Per_Arb   \n4                                   7.807146           RBF       Per_Week   \n5                                  42.885764           RBF      Per_Month   \n6                                 280.212866           RBF        Per_Arb   \n7                                   9.177903           RBF       Per_Week   \n8                                  33.225813           RBF      Per_Month   \n9                                 415.032993           RBF        Per_Arb   \n10                                  7.492886           RBF       Per_Week   \n11                                 35.528365           RBF      Per_Month   \n12                               4398.272332        Mat0.5        Per_Arb   \n13                                  7.280445        Mat0.5       Per_Week   \n14                                 32.884873        Mat0.5      Per_Month   \n15                               5454.527984        Mat0.5        Per_Arb   \n16                                  9.253740        Mat0.5       Per_Week   \n17                                 28.933439        Mat0.5      Per_Month   \n18                               5028.319055        Mat0.5        Per_Arb   \n19                                  7.274124        Mat0.5       Per_Week   \n20                                 18.831912        Mat0.5      Per_Month   \n21                               5449.201708        Mat0.5        Per_Arb   \n22                                  6.669795        Mat0.5       Per_Week   \n23                                 32.162813        Mat0.5      Per_Month   \n24                               4093.514997        Mat1.5        Per_Arb   \n25                                  6.565846        Mat1.5       Per_Week   \n26                                 21.695622        Mat1.5      Per_Month   \n27                               5926.803683        Mat1.5        Per_Arb   \n28                                  6.006009        Mat1.5       Per_Week   \n29                                 30.105351        Mat1.5      Per_Month   \n30                               4997.380667        Mat1.5        Per_Arb   \n31                                  5.686124        Mat1.5       Per_Week   \n32                                 24.910057        Mat1.5      Per_Month   \n33                               4536.034517        Mat1.5        Per_Arb   \n34                                  9.589931        Mat1.5       Per_Week   \n35                                 24.248696        Mat1.5      Per_Month   \n36                               4690.324543        Mat2.5        Per_Arb   \n37                                 10.173702        Mat2.5       Per_Week   \n38                                 33.527309        Mat2.5      Per_Month   \n39                               5938.732134        Mat2.5        Per_Arb   \n40                                  7.240305        Mat2.5       Per_Week   \n41                                 28.611561        Mat2.5      Per_Month   \n42                                261.932361        Mat2.5        Per_Arb   \n43                                 12.916522        Mat2.5       Per_Week   \n44                                 21.847053        Mat2.5      Per_Month   \n45                                307.682334        Mat2.5        Per_Arb   \n46                                  8.431754        Mat2.5       Per_Week   \n47                                 19.468442        Mat2.5      Per_Month   \n\n   scale2_mult_K3          BIC     s1_ls     s2_ls     pk_ls     pk_pr  \n0             RBF -1805.135620  2.833134  0.087118  0.000075  0.220226  \n1             RBF -1827.237061  0.000386  2.457447  2.792247  0.001583  \n2             RBF -2233.627686  0.000293  0.254716  2.288955  0.008738  \n3          Mat0.5 -1298.525146  1.319847  0.032006  1.491903  1.482382  \n4          Mat0.5  -322.171631  1.600245  0.057973  4.177843  0.002056  \n5          Mat0.5  -392.073547  1.264017  0.058467  0.198392  0.011295  \n6          Mat1.5  1953.407471  1.762203  0.010063  0.102558  0.073804  \n7          Mat1.5   509.828369  1.546903  0.011549  4.772974  0.002417  \n8          Mat1.5    47.187729  1.462433  0.016194  0.226457  0.008751  \n9          Mat2.5 -1908.702881  3.312636  0.032085  0.000478  0.109313  \n10         Mat2.5  1500.211792  1.908295  0.028125  4.930425  0.001974  \n11         Mat2.5   698.042236  1.363454  0.028307  0.358978  0.009358  \n12            RBF -1713.608154  0.033583  1.009137  1.117978  1.158434  \n13            RBF  4416.419922  0.485157  1.057406  0.475433  0.001918  \n14            RBF -1367.811768  0.035386  1.203233  1.572044  0.008661  \n15         Mat0.5 -2421.545898  0.060981  0.084893  1.438037  1.436634  \n16         Mat0.5 -1307.643433  0.030418  1.320009  2.859185  0.002437  \n17         Mat0.5  -757.242493  0.128312  0.049358  0.419422  0.007621  \n18         Mat1.5 -1364.527100  0.033105  0.630001  1.355961  1.324378  \n19         Mat1.5 -1322.005127  0.030787  1.538649  2.345045  0.001916  \n20         Mat1.5  -296.835205  0.036069  0.015872  0.673845  0.004960  \n21         Mat2.5 -1798.739136  0.037739  0.743992  1.501362  1.435231  \n22         Mat2.5 -1238.739502  0.031497  1.025941  2.406729  0.001757  \n23         Mat2.5  -707.888000  0.034090  0.032117  0.180048  0.008471  \n24            RBF  3010.300049  0.010082  1.007719  1.121241  1.078166  \n25            RBF  4672.148926  0.141076  1.004241  0.389434  0.001729  \n26            RBF  2490.795166  0.010138  0.023956  0.206529  0.005714  \n27         Mat0.5 -1734.705811  0.798240  0.027663  1.573423  1.561024  \n28         Mat0.5  -250.053970  0.593730  0.055094  4.481592  0.001582  \n29         Mat0.5  -516.528564  0.602008  0.049189  0.484925  0.007929  \n30         Mat1.5  2968.091064  0.010042  0.455721  1.278376  1.316229  \n31         Mat1.5  1809.703369  0.010104  0.033570  3.117956  0.001498  \n32         Mat1.5  1427.461792  0.011544  0.020217  0.327095  0.006561  \n33         Mat2.5  2527.500244  0.010075  0.496206  1.158895  1.194718  \n34         Mat2.5  1960.806396  0.010154  0.032453  3.113066  0.002526  \n35         Mat2.5  1303.167358  0.010878  0.033379  0.271235  0.006387  \n36            RBF   395.543213  0.025056  1.229306  1.559705  1.235355  \n37            RBF   368.221436  0.025101  1.037601  0.697538  0.002680  \n38            RBF  1037.097900  0.025749  0.006820  0.180380  0.008831  \n39         Mat0.5 -1398.571167  0.831241  0.025352  1.574531  1.564166  \n40         Mat0.5  -489.410400  0.473279  0.034579  5.193639  0.001907  \n41         Mat0.5  -402.086670  0.555153  0.044332  0.343048  0.007536  \n42         Mat1.5  1129.827026  1.262705  0.010068  0.106592  0.068989  \n43         Mat1.5  1119.735596  0.025515  0.013156  3.987653  0.003402  \n44         Mat1.5   699.712646  0.027418  0.015048  0.804578  0.005754  \n45         Mat2.5 -2027.209717  3.682471  0.034286  0.000471  0.081039  \n46         Mat2.5  1056.807861  0.025120  0.030425  3.534079  0.002221  \n47         Mat2.5  1630.341187  0.025781  0.030966  0.506552  0.005128  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Kernel</th>\n      <th>Length_Scale_for_smoothing_term_1 (Days)</th>\n      <th>Length_Scale_for_smoothing_term_2 (Days)</th>\n      <th>Length_Scale_for_periodic_term_2 (Days)</th>\n      <th>Period_Length_for_periodic_term_2 (Days)</th>\n      <th>add_scale1_K1</th>\n      <th>scale2_mult_K2</th>\n      <th>scale2_mult_K3</th>\n      <th>BIC</th>\n      <th>s1_ls</th>\n      <th>s2_ls</th>\n      <th>pk_ls</th>\n      <th>pk_pr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Scale(RBF)+Scale(Per_Arb*RBF)</td>\n      <td>10756.675944</td>\n      <td>330.764572</td>\n      <td>0.285057</td>\n      <td>836.139177</td>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>-1805.135620</td>\n      <td>2.833134</td>\n      <td>0.087118</td>\n      <td>0.000075</td>\n      <td>0.220226</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Scale(RBF)+Scale(Per_Week*RBF)</td>\n      <td>1.464003</td>\n      <td>9330.289341</td>\n      <td>10601.436349</td>\n      <td>6.010267</td>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>-1827.237061</td>\n      <td>0.000386</td>\n      <td>2.457447</td>\n      <td>2.792247</td>\n      <td>0.001583</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Scale(RBF)+Scale(Per_Month*RBF)</td>\n      <td>1.112530</td>\n      <td>967.088725</td>\n      <td>8690.569506</td>\n      <td>33.176087</td>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>-2233.627686</td>\n      <td>0.000293</td>\n      <td>0.254716</td>\n      <td>2.288955</td>\n      <td>0.008738</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Scale(RBF)+Scale(Per_Arb*Mat0.5)</td>\n      <td>5011.118188</td>\n      <td>121.518015</td>\n      <td>5664.370060</td>\n      <td>5628.218547</td>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-1298.525146</td>\n      <td>1.319847</td>\n      <td>0.032006</td>\n      <td>1.491903</td>\n      <td>1.482382</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Scale(RBF)+Scale(Per_Week*Mat0.5)</td>\n      <td>6075.714930</td>\n      <td>220.108936</td>\n      <td>15862.187083</td>\n      <td>7.807146</td>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-322.171631</td>\n      <td>1.600245</td>\n      <td>0.057973</td>\n      <td>4.177843</td>\n      <td>0.002056</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Scale(RBF)+Scale(Per_Month*Mat0.5)</td>\n      <td>4799.144787</td>\n      <td>221.984807</td>\n      <td>753.243117</td>\n      <td>42.885764</td>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-392.073547</td>\n      <td>1.264017</td>\n      <td>0.058467</td>\n      <td>0.198392</td>\n      <td>0.011295</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Scale(RBF)+Scale(Per_Arb*Mat1.5)</td>\n      <td>6690.627841</td>\n      <td>38.207175</td>\n      <td>389.385691</td>\n      <td>280.212866</td>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>1953.407471</td>\n      <td>1.762203</td>\n      <td>0.010063</td>\n      <td>0.102558</td>\n      <td>0.073804</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Scale(RBF)+Scale(Per_Week*Mat1.5)</td>\n      <td>5873.190601</td>\n      <td>43.846995</td>\n      <td>18121.744895</td>\n      <td>9.177903</td>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>509.828369</td>\n      <td>1.546903</td>\n      <td>0.011549</td>\n      <td>4.772974</td>\n      <td>0.002417</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Scale(RBF)+Scale(Per_Month*Mat1.5)</td>\n      <td>5552.480236</td>\n      <td>61.485172</td>\n      <td>859.797272</td>\n      <td>33.225813</td>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>47.187729</td>\n      <td>1.462433</td>\n      <td>0.016194</td>\n      <td>0.226457</td>\n      <td>0.008751</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Scale(RBF)+Scale(Per_Arb*Mat2.5)</td>\n      <td>12577.218770</td>\n      <td>121.817838</td>\n      <td>1.816306</td>\n      <td>415.032993</td>\n      <td>RBF</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>-1908.702881</td>\n      <td>3.312636</td>\n      <td>0.032085</td>\n      <td>0.000478</td>\n      <td>0.109313</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Scale(RBF)+Scale(Per_Week*Mat2.5)</td>\n      <td>7245.301506</td>\n      <td>106.783981</td>\n      <td>18719.544291</td>\n      <td>7.492886</td>\n      <td>RBF</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>1500.211792</td>\n      <td>1.908295</td>\n      <td>0.028125</td>\n      <td>4.930425</td>\n      <td>0.001974</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Scale(RBF)+Scale(Per_Month*Mat2.5)</td>\n      <td>5176.679932</td>\n      <td>107.474327</td>\n      <td>1362.947994</td>\n      <td>35.528365</td>\n      <td>RBF</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>698.042236</td>\n      <td>1.363454</td>\n      <td>0.028307</td>\n      <td>0.358978</td>\n      <td>0.009358</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Scale(Mat0.5)+Scale(Per_Arb*RBF)</td>\n      <td>127.506101</td>\n      <td>3831.431239</td>\n      <td>4244.671627</td>\n      <td>4398.272332</td>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>-1713.608154</td>\n      <td>0.033583</td>\n      <td>1.009137</td>\n      <td>1.117978</td>\n      <td>1.158434</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Scale(Mat0.5)+Scale(Per_Week*RBF)</td>\n      <td>1842.015284</td>\n      <td>4014.698055</td>\n      <td>1805.097394</td>\n      <td>7.280445</td>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>4416.419922</td>\n      <td>0.485157</td>\n      <td>1.057406</td>\n      <td>0.475433</td>\n      <td>0.001918</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Scale(Mat0.5)+Scale(Per_Month*RBF)</td>\n      <td>134.351948</td>\n      <td>4568.363313</td>\n      <td>5968.643105</td>\n      <td>32.884873</td>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>-1367.811768</td>\n      <td>0.035386</td>\n      <td>1.203233</td>\n      <td>1.572044</td>\n      <td>0.008661</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Scale(Mat0.5)+Scale(Per_Arb*Mat0.5)</td>\n      <td>231.530807</td>\n      <td>322.315168</td>\n      <td>5459.851998</td>\n      <td>5454.527984</td>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-2421.545898</td>\n      <td>0.060981</td>\n      <td>0.084893</td>\n      <td>1.438037</td>\n      <td>1.436634</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Scale(Mat0.5)+Scale(Per_Week*Mat0.5)</td>\n      <td>115.490693</td>\n      <td>5011.731922</td>\n      <td>10855.584100</td>\n      <td>9.253740</td>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-1307.643433</td>\n      <td>0.030418</td>\n      <td>1.320009</td>\n      <td>2.859185</td>\n      <td>0.002437</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Scale(Mat0.5)+Scale(Per_Month*Mat0.5)</td>\n      <td>487.166801</td>\n      <td>187.401082</td>\n      <td>1592.437050</td>\n      <td>28.933439</td>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-757.242493</td>\n      <td>0.128312</td>\n      <td>0.049358</td>\n      <td>0.419422</td>\n      <td>0.007621</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Scale(Mat0.5)+Scale(Per_Arb*Mat1.5)</td>\n      <td>125.690511</td>\n      <td>2391.950722</td>\n      <td>5148.232692</td>\n      <td>5028.319055</td>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>-1364.527100</td>\n      <td>0.033105</td>\n      <td>0.630001</td>\n      <td>1.355961</td>\n      <td>1.324378</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Scale(Mat0.5)+Scale(Per_Week*Mat1.5)</td>\n      <td>116.888837</td>\n      <td>5841.851203</td>\n      <td>8903.529136</td>\n      <td>7.274124</td>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>-1322.005127</td>\n      <td>0.030787</td>\n      <td>1.538649</td>\n      <td>2.345045</td>\n      <td>0.001916</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Scale(Mat0.5)+Scale(Per_Month*Mat1.5)</td>\n      <td>136.946248</td>\n      <td>60.261670</td>\n      <td>2558.416096</td>\n      <td>18.831912</td>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>-296.835205</td>\n      <td>0.036069</td>\n      <td>0.015872</td>\n      <td>0.673845</td>\n      <td>0.004960</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Scale(Mat0.5)+Scale(Per_Arb*Mat2.5)</td>\n      <td>143.284935</td>\n      <td>2824.744853</td>\n      <td>5700.281691</td>\n      <td>5449.201708</td>\n      <td>Mat0.5</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>-1798.739136</td>\n      <td>0.037739</td>\n      <td>0.743992</td>\n      <td>1.501362</td>\n      <td>1.435231</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Scale(Mat0.5)+Scale(Per_Week*Mat2.5)</td>\n      <td>119.586275</td>\n      <td>3895.232499</td>\n      <td>9137.726887</td>\n      <td>6.669795</td>\n      <td>Mat0.5</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>-1238.739502</td>\n      <td>0.031497</td>\n      <td>1.025941</td>\n      <td>2.406729</td>\n      <td>0.001757</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Scale(Mat0.5)+Scale(Per_Month*Mat2.5)</td>\n      <td>129.431518</td>\n      <td>121.941032</td>\n      <td>683.594912</td>\n      <td>32.162813</td>\n      <td>Mat0.5</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>-707.888000</td>\n      <td>0.034090</td>\n      <td>0.032117</td>\n      <td>0.180048</td>\n      <td>0.008471</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Scale(Mat1.5)+Scale(Per_Arb*RBF)</td>\n      <td>38.277354</td>\n      <td>3826.049292</td>\n      <td>4257.063095</td>\n      <td>4093.514997</td>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>3010.300049</td>\n      <td>0.010082</td>\n      <td>1.007719</td>\n      <td>1.121241</td>\n      <td>1.078166</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Scale(Mat1.5)+Scale(Per_Week*RBF)</td>\n      <td>535.629953</td>\n      <td>3812.843584</td>\n      <td>1478.579631</td>\n      <td>6.565846</td>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>4672.148926</td>\n      <td>0.141076</td>\n      <td>1.004241</td>\n      <td>0.389434</td>\n      <td>0.001729</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Scale(Mat1.5)+Scale(Per_Month*RBF)</td>\n      <td>38.492639</td>\n      <td>90.954760</td>\n      <td>784.138790</td>\n      <td>21.695622</td>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>2490.795166</td>\n      <td>0.010138</td>\n      <td>0.023956</td>\n      <td>0.206529</td>\n      <td>0.005714</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Scale(Mat1.5)+Scale(Per_Arb*Mat0.5)</td>\n      <td>3030.710125</td>\n      <td>105.029607</td>\n      <td>5973.878408</td>\n      <td>5926.803683</td>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-1734.705811</td>\n      <td>0.798240</td>\n      <td>0.027663</td>\n      <td>1.573423</td>\n      <td>1.561024</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Scale(Mat1.5)+Scale(Per_Week*Mat0.5)</td>\n      <td>2254.237419</td>\n      <td>209.177959</td>\n      <td>17015.443607</td>\n      <td>6.006009</td>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-250.053970</td>\n      <td>0.593730</td>\n      <td>0.055094</td>\n      <td>4.481592</td>\n      <td>0.001582</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Scale(Mat1.5)+Scale(Per_Month*Mat0.5)</td>\n      <td>2285.668017</td>\n      <td>186.759314</td>\n      <td>1841.134398</td>\n      <td>30.105351</td>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-516.528564</td>\n      <td>0.602008</td>\n      <td>0.049189</td>\n      <td>0.484925</td>\n      <td>0.007929</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Scale(Mat1.5)+Scale(Per_Arb*Mat1.5)</td>\n      <td>38.126844</td>\n      <td>1730.256263</td>\n      <td>4853.661272</td>\n      <td>4997.380667</td>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>2968.091064</td>\n      <td>0.010042</td>\n      <td>0.455721</td>\n      <td>1.278376</td>\n      <td>1.316229</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Scale(Mat1.5)+Scale(Per_Week*Mat1.5)</td>\n      <td>38.362508</td>\n      <td>127.457856</td>\n      <td>11838.071186</td>\n      <td>5.686124</td>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>1809.703369</td>\n      <td>0.010104</td>\n      <td>0.033570</td>\n      <td>3.117956</td>\n      <td>0.001498</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Scale(Mat1.5)+Scale(Per_Month*Mat1.5)</td>\n      <td>43.828261</td>\n      <td>76.758763</td>\n      <td>1241.894807</td>\n      <td>24.910057</td>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>1427.461792</td>\n      <td>0.011544</td>\n      <td>0.020217</td>\n      <td>0.327095</td>\n      <td>0.006561</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Scale(Mat1.5)+Scale(Per_Arb*Mat2.5)</td>\n      <td>38.252934</td>\n      <td>1883.964350</td>\n      <td>4400.024826</td>\n      <td>4536.034517</td>\n      <td>Mat1.5</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>2527.500244</td>\n      <td>0.010075</td>\n      <td>0.496206</td>\n      <td>1.158895</td>\n      <td>1.194718</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Scale(Mat1.5)+Scale(Per_Week*Mat2.5)</td>\n      <td>38.550601</td>\n      <td>123.214993</td>\n      <td>11819.505257</td>\n      <td>9.589931</td>\n      <td>Mat1.5</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>1960.806396</td>\n      <td>0.010154</td>\n      <td>0.032453</td>\n      <td>3.113066</td>\n      <td>0.002526</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Scale(Mat1.5)+Scale(Per_Month*Mat2.5)</td>\n      <td>41.299257</td>\n      <td>126.730206</td>\n      <td>1029.807123</td>\n      <td>24.248696</td>\n      <td>Mat1.5</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>1303.167358</td>\n      <td>0.010878</td>\n      <td>0.033379</td>\n      <td>0.271235</td>\n      <td>0.006387</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Scale(Mat2.5)+Scale(Per_Arb*RBF)</td>\n      <td>95.132886</td>\n      <td>4667.357917</td>\n      <td>5921.794231</td>\n      <td>4690.324543</td>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>RBF</td>\n      <td>395.543213</td>\n      <td>0.025056</td>\n      <td>1.229306</td>\n      <td>1.559705</td>\n      <td>1.235355</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Scale(Mat2.5)+Scale(Per_Week*RBF)</td>\n      <td>95.302267</td>\n      <td>3939.503777</td>\n      <td>2648.371465</td>\n      <td>10.173702</td>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>RBF</td>\n      <td>368.221436</td>\n      <td>0.025101</td>\n      <td>1.037601</td>\n      <td>0.697538</td>\n      <td>0.002680</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Scale(Mat2.5)+Scale(Per_Month*RBF)</td>\n      <td>97.761909</td>\n      <td>25.893531</td>\n      <td>684.856723</td>\n      <td>33.527309</td>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>RBF</td>\n      <td>1037.097900</td>\n      <td>0.025749</td>\n      <td>0.006820</td>\n      <td>0.180380</td>\n      <td>0.008831</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Scale(Mat2.5)+Scale(Per_Arb*Mat0.5)</td>\n      <td>3156.005256</td>\n      <td>96.256447</td>\n      <td>5978.086293</td>\n      <td>5938.732134</td>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>Mat0.5</td>\n      <td>-1398.571167</td>\n      <td>0.831241</td>\n      <td>0.025352</td>\n      <td>1.574531</td>\n      <td>1.564166</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Scale(Mat2.5)+Scale(Per_Week*Mat0.5)</td>\n      <td>1796.917545</td>\n      <td>131.287150</td>\n      <td>19718.900031</td>\n      <td>7.240305</td>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>Mat0.5</td>\n      <td>-489.410400</td>\n      <td>0.473279</td>\n      <td>0.034579</td>\n      <td>5.193639</td>\n      <td>0.001907</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Scale(Mat2.5)+Scale(Per_Month*Mat0.5)</td>\n      <td>2107.770475</td>\n      <td>168.318785</td>\n      <td>1302.464115</td>\n      <td>28.611561</td>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>Mat0.5</td>\n      <td>-402.086670</td>\n      <td>0.555153</td>\n      <td>0.044332</td>\n      <td>0.343048</td>\n      <td>0.007536</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Scale(Mat2.5)+Scale(Per_Arb*Mat1.5)</td>\n      <td>4794.162492</td>\n      <td>38.224954</td>\n      <td>404.703036</td>\n      <td>261.932361</td>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>Mat1.5</td>\n      <td>1129.827026</td>\n      <td>1.262705</td>\n      <td>0.010068</td>\n      <td>0.106592</td>\n      <td>0.068989</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Scale(Mat2.5)+Scale(Per_Week*Mat1.5)</td>\n      <td>96.875436</td>\n      <td>49.950984</td>\n      <td>15140.084670</td>\n      <td>12.916522</td>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>Mat1.5</td>\n      <td>1119.735596</td>\n      <td>0.025515</td>\n      <td>0.013156</td>\n      <td>3.987653</td>\n      <td>0.003402</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>Scale(Mat2.5)+Scale(Per_Month*Mat1.5)</td>\n      <td>104.099146</td>\n      <td>57.131838</td>\n      <td>3054.774322</td>\n      <td>21.847053</td>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>Mat1.5</td>\n      <td>699.712646</td>\n      <td>0.027418</td>\n      <td>0.015048</td>\n      <td>0.804578</td>\n      <td>0.005754</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Scale(Mat2.5)+Scale(Per_Arb*Mat2.5)</td>\n      <td>13981.388718</td>\n      <td>130.175972</td>\n      <td>1.786906</td>\n      <td>307.682334</td>\n      <td>Mat2.5</td>\n      <td>Per_Arb</td>\n      <td>Mat2.5</td>\n      <td>-2027.209717</td>\n      <td>3.682471</td>\n      <td>0.034286</td>\n      <td>0.000471</td>\n      <td>0.081039</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Scale(Mat2.5)+Scale(Per_Week*Mat2.5)</td>\n      <td>95.375363</td>\n      <td>115.516166</td>\n      <td>13417.980194</td>\n      <td>8.431754</td>\n      <td>Mat2.5</td>\n      <td>Per_Week</td>\n      <td>Mat2.5</td>\n      <td>1056.807861</td>\n      <td>0.025120</td>\n      <td>0.030425</td>\n      <td>3.534079</td>\n      <td>0.002221</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Scale(Mat2.5)+Scale(Per_Month*Mat2.5)</td>\n      <td>97.883186</td>\n      <td>117.569770</td>\n      <td>1923.247901</td>\n      <td>19.468442</td>\n      <td>Mat2.5</td>\n      <td>Per_Month</td>\n      <td>Mat2.5</td>\n      <td>1630.341187</td>\n      <td>0.025781</td>\n      <td>0.030966</td>\n      <td>0.506552</td>\n      <td>0.005128</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def period_convert(x, type_to_convert):\n",
    "    match type_to_convert:\n",
    "        case \"raw\":\n",
    "            return x\n",
    "        case \"seconds\":\n",
    "            return x * scale_factor\n",
    "        case \"minutes\":\n",
    "            return x * scale_factor / 60\n",
    "        case \"hours\":\n",
    "            return x * scale_factor / 60 / 60\n",
    "        case \"days\":\n",
    "            return x * scale_factor / 60 / 60 / 24\n",
    "        case \"weeks\":\n",
    "            return x * scale_factor / 60 / 60 / 24 / 7\n",
    "        case \"months\":\n",
    "            return x * scale_factor / 60 / 60 / 24 / 30\n",
    "        case \"years\":\n",
    "            return x * scale_factor / 60 / 60 / 24 / 365\n",
    "converted_array = []\n",
    "for index, row in bic_out_df.iterrows():\n",
    "    converted_array.append(\n",
    "        [f'Scale({row[\"add_scale1_K1\"]})+Scale({row[\"scale2_mult_K2\"]}*{row[\"scale2_mult_K3\"]})', #row['BIC'],\n",
    "        period_convert(row['s1_ls'], \"days\"),\n",
    "        period_convert(row['s2_ls'], \"days\"),\n",
    "        period_convert(row['pk_ls'], \"days\"),\n",
    "        period_convert(row['pk_pr'],\"days\")])\n",
    "\n",
    "df_with_converstions = pd.DataFrame(\n",
    "    converted_array,\n",
    "    columns=[\n",
    "        \"Kernel\", \"Length_Scale_for_smoothing_term_1 (Days)\",\n",
    "        \"Length_Scale_for_smoothing_term_2 (Days)\", \"Length_Scale_for_periodic_term_2 (Days)\",\"Period_Length_for_periodic_term_2 (Days)\"])\n",
    "joined_bic_table = pd.concat([df_with_converstions, bic_out_df], axis=1)\n",
    "joined_bic_table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T23:14:44.829732Z",
     "end_time": "2023-04-12T23:14:44.926878Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                          Length_Scale_for_smoothing_term_1 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                             \n-2233.627686 RBF           Per_Month      RBF                                             1.112530   \n-1367.811768 Mat0.5        Per_Month      RBF                                           134.351948   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                        487.166801   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                        129.431518   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                       2285.668017   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                       2107.770475   \n-392.073547  RBF           Per_Month      Mat0.5                                       4799.144787   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                        136.946248   \n 47.187729   RBF           Per_Month      Mat1.5                                       5552.480236   \n 698.042236  RBF           Per_Month      Mat2.5                                       5176.679932   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                        104.099146   \n 1037.097900 Mat2.5        Per_Month      RBF                                            97.761909   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                         41.299257   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                         43.828261   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                         97.883186   \n 2490.795166 Mat1.5        Per_Month      RBF                                            38.492639   \n\n                                                          Length_Scale_for_smoothing_term_2 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                             \n-2233.627686 RBF           Per_Month      RBF                                           967.088725   \n-1367.811768 Mat0.5        Per_Month      RBF                                          4568.363313   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                        187.401082   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                        121.941032   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                        186.759314   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                        168.318785   \n-392.073547  RBF           Per_Month      Mat0.5                                        221.984807   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                         60.261670   \n 47.187729   RBF           Per_Month      Mat1.5                                         61.485172   \n 698.042236  RBF           Per_Month      Mat2.5                                        107.474327   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                         57.131838   \n 1037.097900 Mat2.5        Per_Month      RBF                                            25.893531   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                        126.730206   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                         76.758763   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                        117.569770   \n 2490.795166 Mat1.5        Per_Month      RBF                                            90.954760   \n\n                                                          Length_Scale_for_periodic_term_2 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                            \n-2233.627686 RBF           Per_Month      RBF                                         8690.569506   \n-1367.811768 Mat0.5        Per_Month      RBF                                         5968.643105   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                      1592.437050   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                       683.594912   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                      1841.134398   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                      1302.464115   \n-392.073547  RBF           Per_Month      Mat0.5                                       753.243117   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                      2558.416096   \n 47.187729   RBF           Per_Month      Mat1.5                                       859.797272   \n 698.042236  RBF           Per_Month      Mat2.5                                      1362.947994   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                      3054.774322   \n 1037.097900 Mat2.5        Per_Month      RBF                                          684.856723   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                      1029.807123   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                      1241.894807   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                      1923.247901   \n 2490.795166 Mat1.5        Per_Month      RBF                                          784.138790   \n\n                                                          Period_Length_for_periodic_term_2 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                             \n-2233.627686 RBF           Per_Month      RBF                                            33.176087   \n-1367.811768 Mat0.5        Per_Month      RBF                                            32.884873   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                         28.933439   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                         32.162813   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                         30.105351   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                         28.611561   \n-392.073547  RBF           Per_Month      Mat0.5                                         42.885764   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                         18.831912   \n 47.187729   RBF           Per_Month      Mat1.5                                         33.225813   \n 698.042236  RBF           Per_Month      Mat2.5                                         35.528365   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                         21.847053   \n 1037.097900 Mat2.5        Per_Month      RBF                                            33.527309   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                         24.248696   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                         24.910057   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                         19.468442   \n 2490.795166 Mat1.5        Per_Month      RBF                                            21.695622   \n\n                                                             s1_ls     s2_ls  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                       \n-2233.627686 RBF           Per_Month      RBF             0.000293  0.254716   \n-1367.811768 Mat0.5        Per_Month      RBF             0.035386  1.203233   \n-757.242493  Mat0.5        Per_Month      Mat0.5          0.128312  0.049358   \n-707.888000  Mat0.5        Per_Month      Mat2.5          0.034090  0.032117   \n-516.528564  Mat1.5        Per_Month      Mat0.5          0.602008  0.049189   \n-402.086670  Mat2.5        Per_Month      Mat0.5          0.555153  0.044332   \n-392.073547  RBF           Per_Month      Mat0.5          1.264017  0.058467   \n-296.835205  Mat0.5        Per_Month      Mat1.5          0.036069  0.015872   \n 47.187729   RBF           Per_Month      Mat1.5          1.462433  0.016194   \n 698.042236  RBF           Per_Month      Mat2.5          1.363454  0.028307   \n 699.712646  Mat2.5        Per_Month      Mat1.5          0.027418  0.015048   \n 1037.097900 Mat2.5        Per_Month      RBF             0.025749  0.006820   \n 1303.167358 Mat1.5        Per_Month      Mat2.5          0.010878  0.033379   \n 1427.461792 Mat1.5        Per_Month      Mat1.5          0.011544  0.020217   \n 1630.341187 Mat2.5        Per_Month      Mat2.5          0.025781  0.030966   \n 2490.795166 Mat1.5        Per_Month      RBF             0.010138  0.023956   \n\n                                                             pk_ls     pk_pr  \nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                      \n-2233.627686 RBF           Per_Month      RBF             2.288955  0.008738  \n-1367.811768 Mat0.5        Per_Month      RBF             1.572044  0.008661  \n-757.242493  Mat0.5        Per_Month      Mat0.5          0.419422  0.007621  \n-707.888000  Mat0.5        Per_Month      Mat2.5          0.180048  0.008471  \n-516.528564  Mat1.5        Per_Month      Mat0.5          0.484925  0.007929  \n-402.086670  Mat2.5        Per_Month      Mat0.5          0.343048  0.007536  \n-392.073547  RBF           Per_Month      Mat0.5          0.198392  0.011295  \n-296.835205  Mat0.5        Per_Month      Mat1.5          0.673845  0.004960  \n 47.187729   RBF           Per_Month      Mat1.5          0.226457  0.008751  \n 698.042236  RBF           Per_Month      Mat2.5          0.358978  0.009358  \n 699.712646  Mat2.5        Per_Month      Mat1.5          0.804578  0.005754  \n 1037.097900 Mat2.5        Per_Month      RBF             0.180380  0.008831  \n 1303.167358 Mat1.5        Per_Month      Mat2.5          0.271235  0.006387  \n 1427.461792 Mat1.5        Per_Month      Mat1.5          0.327095  0.006561  \n 1630.341187 Mat2.5        Per_Month      Mat2.5          0.506552  0.005128  \n 2490.795166 Mat1.5        Per_Month      RBF             0.206529  0.005714  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Length_Scale_for_smoothing_term_1 (Days)</th>\n      <th>Length_Scale_for_smoothing_term_2 (Days)</th>\n      <th>Length_Scale_for_periodic_term_2 (Days)</th>\n      <th>Period_Length_for_periodic_term_2 (Days)</th>\n      <th>s1_ls</th>\n      <th>s2_ls</th>\n      <th>pk_ls</th>\n      <th>pk_pr</th>\n    </tr>\n    <tr>\n      <th>BIC</th>\n      <th>add_scale1_K1</th>\n      <th>scale2_mult_K2</th>\n      <th>scale2_mult_K3</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-2233.627686</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>1.112530</td>\n      <td>967.088725</td>\n      <td>8690.569506</td>\n      <td>33.176087</td>\n      <td>0.000293</td>\n      <td>0.254716</td>\n      <td>2.288955</td>\n      <td>0.008738</td>\n    </tr>\n    <tr>\n      <th>-1367.811768</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>134.351948</td>\n      <td>4568.363313</td>\n      <td>5968.643105</td>\n      <td>32.884873</td>\n      <td>0.035386</td>\n      <td>1.203233</td>\n      <td>1.572044</td>\n      <td>0.008661</td>\n    </tr>\n    <tr>\n      <th>-757.242493</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>487.166801</td>\n      <td>187.401082</td>\n      <td>1592.437050</td>\n      <td>28.933439</td>\n      <td>0.128312</td>\n      <td>0.049358</td>\n      <td>0.419422</td>\n      <td>0.007621</td>\n    </tr>\n    <tr>\n      <th>-707.888000</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>129.431518</td>\n      <td>121.941032</td>\n      <td>683.594912</td>\n      <td>32.162813</td>\n      <td>0.034090</td>\n      <td>0.032117</td>\n      <td>0.180048</td>\n      <td>0.008471</td>\n    </tr>\n    <tr>\n      <th>-516.528564</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>2285.668017</td>\n      <td>186.759314</td>\n      <td>1841.134398</td>\n      <td>30.105351</td>\n      <td>0.602008</td>\n      <td>0.049189</td>\n      <td>0.484925</td>\n      <td>0.007929</td>\n    </tr>\n    <tr>\n      <th>-402.086670</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>2107.770475</td>\n      <td>168.318785</td>\n      <td>1302.464115</td>\n      <td>28.611561</td>\n      <td>0.555153</td>\n      <td>0.044332</td>\n      <td>0.343048</td>\n      <td>0.007536</td>\n    </tr>\n    <tr>\n      <th>-392.073547</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>4799.144787</td>\n      <td>221.984807</td>\n      <td>753.243117</td>\n      <td>42.885764</td>\n      <td>1.264017</td>\n      <td>0.058467</td>\n      <td>0.198392</td>\n      <td>0.011295</td>\n    </tr>\n    <tr>\n      <th>-296.835205</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>136.946248</td>\n      <td>60.261670</td>\n      <td>2558.416096</td>\n      <td>18.831912</td>\n      <td>0.036069</td>\n      <td>0.015872</td>\n      <td>0.673845</td>\n      <td>0.004960</td>\n    </tr>\n    <tr>\n      <th>47.187729</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>5552.480236</td>\n      <td>61.485172</td>\n      <td>859.797272</td>\n      <td>33.225813</td>\n      <td>1.462433</td>\n      <td>0.016194</td>\n      <td>0.226457</td>\n      <td>0.008751</td>\n    </tr>\n    <tr>\n      <th>698.042236</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>5176.679932</td>\n      <td>107.474327</td>\n      <td>1362.947994</td>\n      <td>35.528365</td>\n      <td>1.363454</td>\n      <td>0.028307</td>\n      <td>0.358978</td>\n      <td>0.009358</td>\n    </tr>\n    <tr>\n      <th>699.712646</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>104.099146</td>\n      <td>57.131838</td>\n      <td>3054.774322</td>\n      <td>21.847053</td>\n      <td>0.027418</td>\n      <td>0.015048</td>\n      <td>0.804578</td>\n      <td>0.005754</td>\n    </tr>\n    <tr>\n      <th>1037.097900</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>97.761909</td>\n      <td>25.893531</td>\n      <td>684.856723</td>\n      <td>33.527309</td>\n      <td>0.025749</td>\n      <td>0.006820</td>\n      <td>0.180380</td>\n      <td>0.008831</td>\n    </tr>\n    <tr>\n      <th>1303.167358</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>41.299257</td>\n      <td>126.730206</td>\n      <td>1029.807123</td>\n      <td>24.248696</td>\n      <td>0.010878</td>\n      <td>0.033379</td>\n      <td>0.271235</td>\n      <td>0.006387</td>\n    </tr>\n    <tr>\n      <th>1427.461792</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>43.828261</td>\n      <td>76.758763</td>\n      <td>1241.894807</td>\n      <td>24.910057</td>\n      <td>0.011544</td>\n      <td>0.020217</td>\n      <td>0.327095</td>\n      <td>0.006561</td>\n    </tr>\n    <tr>\n      <th>1630.341187</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>97.883186</td>\n      <td>117.569770</td>\n      <td>1923.247901</td>\n      <td>19.468442</td>\n      <td>0.025781</td>\n      <td>0.030966</td>\n      <td>0.506552</td>\n      <td>0.005128</td>\n    </tr>\n    <tr>\n      <th>2490.795166</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>38.492639</td>\n      <td>90.954760</td>\n      <td>784.138790</td>\n      <td>21.695622</td>\n      <td>0.010138</td>\n      <td>0.023956</td>\n      <td>0.206529</td>\n      <td>0.005714</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(joined_bic_table.groupby(\"add_scale1_K1\").mean())\n",
    "# print(joined_bic_table.groupby(\"scale2_mult_K2\").mean())\n",
    "# print(joined_bic_table.groupby(\"scale2_mult_K3\").mean())\n",
    "joined_bic_table.groupby(['BIC','add_scale1_K1']).min(['BIC'])\n",
    "joined_bic_table.groupby(['BIC','scale2_mult_K2']).min(['BIC'])\n",
    "joined_bic_table.groupby(['BIC','scale2_mult_K3']).min(['BIC'])\n",
    "joined_bic_table.loc[joined_bic_table['scale2_mult_K2']==\"Per_Month\"].groupby(['BIC','add_scale1_K1','scale2_mult_K2', 'scale2_mult_K3']).min(['BIC'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T23:15:46.217052Z",
     "end_time": "2023-04-12T23:15:46.276435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                          Length_Scale_for_smoothing_term_1 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                             \n-2421.545898 Mat0.5        Per_Arb        Mat0.5                                        231.530807   \n-2233.627686 RBF           Per_Month      RBF                                             1.112530   \n-2027.209717 Mat2.5        Per_Arb        Mat2.5                                      13981.388718   \n-1908.702881 RBF           Per_Arb        Mat2.5                                      12577.218770   \n-1827.237061 RBF           Per_Week       RBF                                             1.464003   \n-1805.135620 RBF           Per_Arb        RBF                                         10756.675944   \n-1798.739136 Mat0.5        Per_Arb        Mat2.5                                        143.284935   \n-1734.705811 Mat1.5        Per_Arb        Mat0.5                                       3030.710125   \n-1713.608154 Mat0.5        Per_Arb        RBF                                           127.506101   \n-1398.571167 Mat2.5        Per_Arb        Mat0.5                                       3156.005256   \n-1367.811768 Mat0.5        Per_Month      RBF                                           134.351948   \n-1364.527100 Mat0.5        Per_Arb        Mat1.5                                        125.690511   \n-1322.005127 Mat0.5        Per_Week       Mat1.5                                        116.888837   \n-1307.643433 Mat0.5        Per_Week       Mat0.5                                        115.490693   \n-1298.525146 RBF           Per_Arb        Mat0.5                                       5011.118188   \n-1238.739502 Mat0.5        Per_Week       Mat2.5                                        119.586275   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                        487.166801   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                        129.431518   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                       2285.668017   \n-489.410400  Mat2.5        Per_Week       Mat0.5                                       1796.917545   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                       2107.770475   \n-392.073547  RBF           Per_Month      Mat0.5                                       4799.144787   \n-322.171631  RBF           Per_Week       Mat0.5                                       6075.714930   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                        136.946248   \n-250.053970  Mat1.5        Per_Week       Mat0.5                                       2254.237419   \n 47.187729   RBF           Per_Month      Mat1.5                                       5552.480236   \n 368.221436  Mat2.5        Per_Week       RBF                                            95.302267   \n 395.543213  Mat2.5        Per_Arb        RBF                                            95.132886   \n 509.828369  RBF           Per_Week       Mat1.5                                       5873.190601   \n 698.042236  RBF           Per_Month      Mat2.5                                       5176.679932   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                        104.099146   \n 1037.097900 Mat2.5        Per_Month      RBF                                            97.761909   \n 1056.807861 Mat2.5        Per_Week       Mat2.5                                         95.375363   \n 1119.735596 Mat2.5        Per_Week       Mat1.5                                         96.875436   \n 1129.827026 Mat2.5        Per_Arb        Mat1.5                                       4794.162492   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                         41.299257   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                         43.828261   \n 1500.211792 RBF           Per_Week       Mat2.5                                       7245.301506   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                         97.883186   \n 1809.703369 Mat1.5        Per_Week       Mat1.5                                         38.362508   \n 1953.407471 RBF           Per_Arb        Mat1.5                                       6690.627841   \n 1960.806396 Mat1.5        Per_Week       Mat2.5                                         38.550601   \n 2490.795166 Mat1.5        Per_Month      RBF                                            38.492639   \n 2527.500244 Mat1.5        Per_Arb        Mat2.5                                         38.252934   \n 2968.091064 Mat1.5        Per_Arb        Mat1.5                                         38.126844   \n 3010.300049 Mat1.5        Per_Arb        RBF                                            38.277354   \n 4416.419922 Mat0.5        Per_Week       RBF                                          1842.015284   \n 4672.148926 Mat1.5        Per_Week       RBF                                           535.629953   \n\n                                                          Length_Scale_for_smoothing_term_2 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                             \n-2421.545898 Mat0.5        Per_Arb        Mat0.5                                        322.315168   \n-2233.627686 RBF           Per_Month      RBF                                           967.088725   \n-2027.209717 Mat2.5        Per_Arb        Mat2.5                                        130.175972   \n-1908.702881 RBF           Per_Arb        Mat2.5                                        121.817838   \n-1827.237061 RBF           Per_Week       RBF                                          9330.289341   \n-1805.135620 RBF           Per_Arb        RBF                                           330.764572   \n-1798.739136 Mat0.5        Per_Arb        Mat2.5                                       2824.744853   \n-1734.705811 Mat1.5        Per_Arb        Mat0.5                                        105.029607   \n-1713.608154 Mat0.5        Per_Arb        RBF                                          3831.431239   \n-1398.571167 Mat2.5        Per_Arb        Mat0.5                                         96.256447   \n-1367.811768 Mat0.5        Per_Month      RBF                                          4568.363313   \n-1364.527100 Mat0.5        Per_Arb        Mat1.5                                       2391.950722   \n-1322.005127 Mat0.5        Per_Week       Mat1.5                                       5841.851203   \n-1307.643433 Mat0.5        Per_Week       Mat0.5                                       5011.731922   \n-1298.525146 RBF           Per_Arb        Mat0.5                                        121.518015   \n-1238.739502 Mat0.5        Per_Week       Mat2.5                                       3895.232499   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                        187.401082   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                        121.941032   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                        186.759314   \n-489.410400  Mat2.5        Per_Week       Mat0.5                                        131.287150   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                        168.318785   \n-392.073547  RBF           Per_Month      Mat0.5                                        221.984807   \n-322.171631  RBF           Per_Week       Mat0.5                                        220.108936   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                         60.261670   \n-250.053970  Mat1.5        Per_Week       Mat0.5                                        209.177959   \n 47.187729   RBF           Per_Month      Mat1.5                                         61.485172   \n 368.221436  Mat2.5        Per_Week       RBF                                          3939.503777   \n 395.543213  Mat2.5        Per_Arb        RBF                                          4667.357917   \n 509.828369  RBF           Per_Week       Mat1.5                                         43.846995   \n 698.042236  RBF           Per_Month      Mat2.5                                        107.474327   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                         57.131838   \n 1037.097900 Mat2.5        Per_Month      RBF                                            25.893531   \n 1056.807861 Mat2.5        Per_Week       Mat2.5                                        115.516166   \n 1119.735596 Mat2.5        Per_Week       Mat1.5                                         49.950984   \n 1129.827026 Mat2.5        Per_Arb        Mat1.5                                         38.224954   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                        126.730206   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                         76.758763   \n 1500.211792 RBF           Per_Week       Mat2.5                                        106.783981   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                        117.569770   \n 1809.703369 Mat1.5        Per_Week       Mat1.5                                        127.457856   \n 1953.407471 RBF           Per_Arb        Mat1.5                                         38.207175   \n 1960.806396 Mat1.5        Per_Week       Mat2.5                                        123.214993   \n 2490.795166 Mat1.5        Per_Month      RBF                                            90.954760   \n 2527.500244 Mat1.5        Per_Arb        Mat2.5                                       1883.964350   \n 2968.091064 Mat1.5        Per_Arb        Mat1.5                                       1730.256263   \n 3010.300049 Mat1.5        Per_Arb        RBF                                          3826.049292   \n 4416.419922 Mat0.5        Per_Week       RBF                                          4014.698055   \n 4672.148926 Mat1.5        Per_Week       RBF                                          3812.843584   \n\n                                                          Length_Scale_for_periodic_term_2 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                            \n-2421.545898 Mat0.5        Per_Arb        Mat0.5                                      5459.851998   \n-2233.627686 RBF           Per_Month      RBF                                         8690.569506   \n-2027.209717 Mat2.5        Per_Arb        Mat2.5                                         1.786906   \n-1908.702881 RBF           Per_Arb        Mat2.5                                         1.816306   \n-1827.237061 RBF           Per_Week       RBF                                        10601.436349   \n-1805.135620 RBF           Per_Arb        RBF                                            0.285057   \n-1798.739136 Mat0.5        Per_Arb        Mat2.5                                      5700.281691   \n-1734.705811 Mat1.5        Per_Arb        Mat0.5                                      5973.878408   \n-1713.608154 Mat0.5        Per_Arb        RBF                                         4244.671627   \n-1398.571167 Mat2.5        Per_Arb        Mat0.5                                      5978.086293   \n-1367.811768 Mat0.5        Per_Month      RBF                                         5968.643105   \n-1364.527100 Mat0.5        Per_Arb        Mat1.5                                      5148.232692   \n-1322.005127 Mat0.5        Per_Week       Mat1.5                                      8903.529136   \n-1307.643433 Mat0.5        Per_Week       Mat0.5                                     10855.584100   \n-1298.525146 RBF           Per_Arb        Mat0.5                                      5664.370060   \n-1238.739502 Mat0.5        Per_Week       Mat2.5                                      9137.726887   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                      1592.437050   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                       683.594912   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                      1841.134398   \n-489.410400  Mat2.5        Per_Week       Mat0.5                                     19718.900031   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                      1302.464115   \n-392.073547  RBF           Per_Month      Mat0.5                                       753.243117   \n-322.171631  RBF           Per_Week       Mat0.5                                     15862.187083   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                      2558.416096   \n-250.053970  Mat1.5        Per_Week       Mat0.5                                     17015.443607   \n 47.187729   RBF           Per_Month      Mat1.5                                       859.797272   \n 368.221436  Mat2.5        Per_Week       RBF                                         2648.371465   \n 395.543213  Mat2.5        Per_Arb        RBF                                         5921.794231   \n 509.828369  RBF           Per_Week       Mat1.5                                     18121.744895   \n 698.042236  RBF           Per_Month      Mat2.5                                      1362.947994   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                      3054.774322   \n 1037.097900 Mat2.5        Per_Month      RBF                                          684.856723   \n 1056.807861 Mat2.5        Per_Week       Mat2.5                                     13417.980194   \n 1119.735596 Mat2.5        Per_Week       Mat1.5                                     15140.084670   \n 1129.827026 Mat2.5        Per_Arb        Mat1.5                                       404.703036   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                      1029.807123   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                      1241.894807   \n 1500.211792 RBF           Per_Week       Mat2.5                                     18719.544291   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                      1923.247901   \n 1809.703369 Mat1.5        Per_Week       Mat1.5                                     11838.071186   \n 1953.407471 RBF           Per_Arb        Mat1.5                                       389.385691   \n 1960.806396 Mat1.5        Per_Week       Mat2.5                                     11819.505257   \n 2490.795166 Mat1.5        Per_Month      RBF                                          784.138790   \n 2527.500244 Mat1.5        Per_Arb        Mat2.5                                      4400.024826   \n 2968.091064 Mat1.5        Per_Arb        Mat1.5                                      4853.661272   \n 3010.300049 Mat1.5        Per_Arb        RBF                                         4257.063095   \n 4416.419922 Mat0.5        Per_Week       RBF                                         1805.097394   \n 4672.148926 Mat1.5        Per_Week       RBF                                         1478.579631   \n\n                                                          Period_Length_for_periodic_term_2 (Days)  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                                             \n-2421.545898 Mat0.5        Per_Arb        Mat0.5                                       5454.527984   \n-2233.627686 RBF           Per_Month      RBF                                            33.176087   \n-2027.209717 Mat2.5        Per_Arb        Mat2.5                                        307.682334   \n-1908.702881 RBF           Per_Arb        Mat2.5                                        415.032993   \n-1827.237061 RBF           Per_Week       RBF                                             6.010267   \n-1805.135620 RBF           Per_Arb        RBF                                           836.139177   \n-1798.739136 Mat0.5        Per_Arb        Mat2.5                                       5449.201708   \n-1734.705811 Mat1.5        Per_Arb        Mat0.5                                       5926.803683   \n-1713.608154 Mat0.5        Per_Arb        RBF                                          4398.272332   \n-1398.571167 Mat2.5        Per_Arb        Mat0.5                                       5938.732134   \n-1367.811768 Mat0.5        Per_Month      RBF                                            32.884873   \n-1364.527100 Mat0.5        Per_Arb        Mat1.5                                       5028.319055   \n-1322.005127 Mat0.5        Per_Week       Mat1.5                                          7.274124   \n-1307.643433 Mat0.5        Per_Week       Mat0.5                                          9.253740   \n-1298.525146 RBF           Per_Arb        Mat0.5                                       5628.218547   \n-1238.739502 Mat0.5        Per_Week       Mat2.5                                          6.669795   \n-757.242493  Mat0.5        Per_Month      Mat0.5                                         28.933439   \n-707.888000  Mat0.5        Per_Month      Mat2.5                                         32.162813   \n-516.528564  Mat1.5        Per_Month      Mat0.5                                         30.105351   \n-489.410400  Mat2.5        Per_Week       Mat0.5                                          7.240305   \n-402.086670  Mat2.5        Per_Month      Mat0.5                                         28.611561   \n-392.073547  RBF           Per_Month      Mat0.5                                         42.885764   \n-322.171631  RBF           Per_Week       Mat0.5                                          7.807146   \n-296.835205  Mat0.5        Per_Month      Mat1.5                                         18.831912   \n-250.053970  Mat1.5        Per_Week       Mat0.5                                          6.006009   \n 47.187729   RBF           Per_Month      Mat1.5                                         33.225813   \n 368.221436  Mat2.5        Per_Week       RBF                                            10.173702   \n 395.543213  Mat2.5        Per_Arb        RBF                                          4690.324543   \n 509.828369  RBF           Per_Week       Mat1.5                                          9.177903   \n 698.042236  RBF           Per_Month      Mat2.5                                         35.528365   \n 699.712646  Mat2.5        Per_Month      Mat1.5                                         21.847053   \n 1037.097900 Mat2.5        Per_Month      RBF                                            33.527309   \n 1056.807861 Mat2.5        Per_Week       Mat2.5                                          8.431754   \n 1119.735596 Mat2.5        Per_Week       Mat1.5                                         12.916522   \n 1129.827026 Mat2.5        Per_Arb        Mat1.5                                        261.932361   \n 1303.167358 Mat1.5        Per_Month      Mat2.5                                         24.248696   \n 1427.461792 Mat1.5        Per_Month      Mat1.5                                         24.910057   \n 1500.211792 RBF           Per_Week       Mat2.5                                          7.492886   \n 1630.341187 Mat2.5        Per_Month      Mat2.5                                         19.468442   \n 1809.703369 Mat1.5        Per_Week       Mat1.5                                          5.686124   \n 1953.407471 RBF           Per_Arb        Mat1.5                                        280.212866   \n 1960.806396 Mat1.5        Per_Week       Mat2.5                                          9.589931   \n 2490.795166 Mat1.5        Per_Month      RBF                                            21.695622   \n 2527.500244 Mat1.5        Per_Arb        Mat2.5                                       4536.034517   \n 2968.091064 Mat1.5        Per_Arb        Mat1.5                                       4997.380667   \n 3010.300049 Mat1.5        Per_Arb        RBF                                          4093.514997   \n 4416.419922 Mat0.5        Per_Week       RBF                                             7.280445   \n 4672.148926 Mat1.5        Per_Week       RBF                                             6.565846   \n\n                                                             s1_ls     s2_ls  \\\nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                       \n-2421.545898 Mat0.5        Per_Arb        Mat0.5          0.060981  0.084893   \n-2233.627686 RBF           Per_Month      RBF             0.000293  0.254716   \n-2027.209717 Mat2.5        Per_Arb        Mat2.5          3.682471  0.034286   \n-1908.702881 RBF           Per_Arb        Mat2.5          3.312636  0.032085   \n-1827.237061 RBF           Per_Week       RBF             0.000386  2.457447   \n-1805.135620 RBF           Per_Arb        RBF             2.833134  0.087118   \n-1798.739136 Mat0.5        Per_Arb        Mat2.5          0.037739  0.743992   \n-1734.705811 Mat1.5        Per_Arb        Mat0.5          0.798240  0.027663   \n-1713.608154 Mat0.5        Per_Arb        RBF             0.033583  1.009137   \n-1398.571167 Mat2.5        Per_Arb        Mat0.5          0.831241  0.025352   \n-1367.811768 Mat0.5        Per_Month      RBF             0.035386  1.203233   \n-1364.527100 Mat0.5        Per_Arb        Mat1.5          0.033105  0.630001   \n-1322.005127 Mat0.5        Per_Week       Mat1.5          0.030787  1.538649   \n-1307.643433 Mat0.5        Per_Week       Mat0.5          0.030418  1.320009   \n-1298.525146 RBF           Per_Arb        Mat0.5          1.319847  0.032006   \n-1238.739502 Mat0.5        Per_Week       Mat2.5          0.031497  1.025941   \n-757.242493  Mat0.5        Per_Month      Mat0.5          0.128312  0.049358   \n-707.888000  Mat0.5        Per_Month      Mat2.5          0.034090  0.032117   \n-516.528564  Mat1.5        Per_Month      Mat0.5          0.602008  0.049189   \n-489.410400  Mat2.5        Per_Week       Mat0.5          0.473279  0.034579   \n-402.086670  Mat2.5        Per_Month      Mat0.5          0.555153  0.044332   \n-392.073547  RBF           Per_Month      Mat0.5          1.264017  0.058467   \n-322.171631  RBF           Per_Week       Mat0.5          1.600245  0.057973   \n-296.835205  Mat0.5        Per_Month      Mat1.5          0.036069  0.015872   \n-250.053970  Mat1.5        Per_Week       Mat0.5          0.593730  0.055094   \n 47.187729   RBF           Per_Month      Mat1.5          1.462433  0.016194   \n 368.221436  Mat2.5        Per_Week       RBF             0.025101  1.037601   \n 395.543213  Mat2.5        Per_Arb        RBF             0.025056  1.229306   \n 509.828369  RBF           Per_Week       Mat1.5          1.546903  0.011549   \n 698.042236  RBF           Per_Month      Mat2.5          1.363454  0.028307   \n 699.712646  Mat2.5        Per_Month      Mat1.5          0.027418  0.015048   \n 1037.097900 Mat2.5        Per_Month      RBF             0.025749  0.006820   \n 1056.807861 Mat2.5        Per_Week       Mat2.5          0.025120  0.030425   \n 1119.735596 Mat2.5        Per_Week       Mat1.5          0.025515  0.013156   \n 1129.827026 Mat2.5        Per_Arb        Mat1.5          1.262705  0.010068   \n 1303.167358 Mat1.5        Per_Month      Mat2.5          0.010878  0.033379   \n 1427.461792 Mat1.5        Per_Month      Mat1.5          0.011544  0.020217   \n 1500.211792 RBF           Per_Week       Mat2.5          1.908295  0.028125   \n 1630.341187 Mat2.5        Per_Month      Mat2.5          0.025781  0.030966   \n 1809.703369 Mat1.5        Per_Week       Mat1.5          0.010104  0.033570   \n 1953.407471 RBF           Per_Arb        Mat1.5          1.762203  0.010063   \n 1960.806396 Mat1.5        Per_Week       Mat2.5          0.010154  0.032453   \n 2490.795166 Mat1.5        Per_Month      RBF             0.010138  0.023956   \n 2527.500244 Mat1.5        Per_Arb        Mat2.5          0.010075  0.496206   \n 2968.091064 Mat1.5        Per_Arb        Mat1.5          0.010042  0.455721   \n 3010.300049 Mat1.5        Per_Arb        RBF             0.010082  1.007719   \n 4416.419922 Mat0.5        Per_Week       RBF             0.485157  1.057406   \n 4672.148926 Mat1.5        Per_Week       RBF             0.141076  1.004241   \n\n                                                             pk_ls     pk_pr  \nBIC          add_scale1_K1 scale2_mult_K2 scale2_mult_K3                      \n-2421.545898 Mat0.5        Per_Arb        Mat0.5          1.438037  1.436634  \n-2233.627686 RBF           Per_Month      RBF             2.288955  0.008738  \n-2027.209717 Mat2.5        Per_Arb        Mat2.5          0.000471  0.081039  \n-1908.702881 RBF           Per_Arb        Mat2.5          0.000478  0.109313  \n-1827.237061 RBF           Per_Week       RBF             2.792247  0.001583  \n-1805.135620 RBF           Per_Arb        RBF             0.000075  0.220226  \n-1798.739136 Mat0.5        Per_Arb        Mat2.5          1.501362  1.435231  \n-1734.705811 Mat1.5        Per_Arb        Mat0.5          1.573423  1.561024  \n-1713.608154 Mat0.5        Per_Arb        RBF             1.117978  1.158434  \n-1398.571167 Mat2.5        Per_Arb        Mat0.5          1.574531  1.564166  \n-1367.811768 Mat0.5        Per_Month      RBF             1.572044  0.008661  \n-1364.527100 Mat0.5        Per_Arb        Mat1.5          1.355961  1.324378  \n-1322.005127 Mat0.5        Per_Week       Mat1.5          2.345045  0.001916  \n-1307.643433 Mat0.5        Per_Week       Mat0.5          2.859185  0.002437  \n-1298.525146 RBF           Per_Arb        Mat0.5          1.491903  1.482382  \n-1238.739502 Mat0.5        Per_Week       Mat2.5          2.406729  0.001757  \n-757.242493  Mat0.5        Per_Month      Mat0.5          0.419422  0.007621  \n-707.888000  Mat0.5        Per_Month      Mat2.5          0.180048  0.008471  \n-516.528564  Mat1.5        Per_Month      Mat0.5          0.484925  0.007929  \n-489.410400  Mat2.5        Per_Week       Mat0.5          5.193639  0.001907  \n-402.086670  Mat2.5        Per_Month      Mat0.5          0.343048  0.007536  \n-392.073547  RBF           Per_Month      Mat0.5          0.198392  0.011295  \n-322.171631  RBF           Per_Week       Mat0.5          4.177843  0.002056  \n-296.835205  Mat0.5        Per_Month      Mat1.5          0.673845  0.004960  \n-250.053970  Mat1.5        Per_Week       Mat0.5          4.481592  0.001582  \n 47.187729   RBF           Per_Month      Mat1.5          0.226457  0.008751  \n 368.221436  Mat2.5        Per_Week       RBF             0.697538  0.002680  \n 395.543213  Mat2.5        Per_Arb        RBF             1.559705  1.235355  \n 509.828369  RBF           Per_Week       Mat1.5          4.772974  0.002417  \n 698.042236  RBF           Per_Month      Mat2.5          0.358978  0.009358  \n 699.712646  Mat2.5        Per_Month      Mat1.5          0.804578  0.005754  \n 1037.097900 Mat2.5        Per_Month      RBF             0.180380  0.008831  \n 1056.807861 Mat2.5        Per_Week       Mat2.5          3.534079  0.002221  \n 1119.735596 Mat2.5        Per_Week       Mat1.5          3.987653  0.003402  \n 1129.827026 Mat2.5        Per_Arb        Mat1.5          0.106592  0.068989  \n 1303.167358 Mat1.5        Per_Month      Mat2.5          0.271235  0.006387  \n 1427.461792 Mat1.5        Per_Month      Mat1.5          0.327095  0.006561  \n 1500.211792 RBF           Per_Week       Mat2.5          4.930425  0.001974  \n 1630.341187 Mat2.5        Per_Month      Mat2.5          0.506552  0.005128  \n 1809.703369 Mat1.5        Per_Week       Mat1.5          3.117956  0.001498  \n 1953.407471 RBF           Per_Arb        Mat1.5          0.102558  0.073804  \n 1960.806396 Mat1.5        Per_Week       Mat2.5          3.113066  0.002526  \n 2490.795166 Mat1.5        Per_Month      RBF             0.206529  0.005714  \n 2527.500244 Mat1.5        Per_Arb        Mat2.5          1.158895  1.194718  \n 2968.091064 Mat1.5        Per_Arb        Mat1.5          1.278376  1.316229  \n 3010.300049 Mat1.5        Per_Arb        RBF             1.121241  1.078166  \n 4416.419922 Mat0.5        Per_Week       RBF             0.475433  0.001918  \n 4672.148926 Mat1.5        Per_Week       RBF             0.389434  0.001729  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Length_Scale_for_smoothing_term_1 (Days)</th>\n      <th>Length_Scale_for_smoothing_term_2 (Days)</th>\n      <th>Length_Scale_for_periodic_term_2 (Days)</th>\n      <th>Period_Length_for_periodic_term_2 (Days)</th>\n      <th>s1_ls</th>\n      <th>s2_ls</th>\n      <th>pk_ls</th>\n      <th>pk_pr</th>\n    </tr>\n    <tr>\n      <th>BIC</th>\n      <th>add_scale1_K1</th>\n      <th>scale2_mult_K2</th>\n      <th>scale2_mult_K3</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-2421.545898</th>\n      <th>Mat0.5</th>\n      <th>Per_Arb</th>\n      <th>Mat0.5</th>\n      <td>231.530807</td>\n      <td>322.315168</td>\n      <td>5459.851998</td>\n      <td>5454.527984</td>\n      <td>0.060981</td>\n      <td>0.084893</td>\n      <td>1.438037</td>\n      <td>1.436634</td>\n    </tr>\n    <tr>\n      <th>-2233.627686</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>1.112530</td>\n      <td>967.088725</td>\n      <td>8690.569506</td>\n      <td>33.176087</td>\n      <td>0.000293</td>\n      <td>0.254716</td>\n      <td>2.288955</td>\n      <td>0.008738</td>\n    </tr>\n    <tr>\n      <th>-2027.209717</th>\n      <th>Mat2.5</th>\n      <th>Per_Arb</th>\n      <th>Mat2.5</th>\n      <td>13981.388718</td>\n      <td>130.175972</td>\n      <td>1.786906</td>\n      <td>307.682334</td>\n      <td>3.682471</td>\n      <td>0.034286</td>\n      <td>0.000471</td>\n      <td>0.081039</td>\n    </tr>\n    <tr>\n      <th>-1908.702881</th>\n      <th>RBF</th>\n      <th>Per_Arb</th>\n      <th>Mat2.5</th>\n      <td>12577.218770</td>\n      <td>121.817838</td>\n      <td>1.816306</td>\n      <td>415.032993</td>\n      <td>3.312636</td>\n      <td>0.032085</td>\n      <td>0.000478</td>\n      <td>0.109313</td>\n    </tr>\n    <tr>\n      <th>-1827.237061</th>\n      <th>RBF</th>\n      <th>Per_Week</th>\n      <th>RBF</th>\n      <td>1.464003</td>\n      <td>9330.289341</td>\n      <td>10601.436349</td>\n      <td>6.010267</td>\n      <td>0.000386</td>\n      <td>2.457447</td>\n      <td>2.792247</td>\n      <td>0.001583</td>\n    </tr>\n    <tr>\n      <th>-1805.135620</th>\n      <th>RBF</th>\n      <th>Per_Arb</th>\n      <th>RBF</th>\n      <td>10756.675944</td>\n      <td>330.764572</td>\n      <td>0.285057</td>\n      <td>836.139177</td>\n      <td>2.833134</td>\n      <td>0.087118</td>\n      <td>0.000075</td>\n      <td>0.220226</td>\n    </tr>\n    <tr>\n      <th>-1798.739136</th>\n      <th>Mat0.5</th>\n      <th>Per_Arb</th>\n      <th>Mat2.5</th>\n      <td>143.284935</td>\n      <td>2824.744853</td>\n      <td>5700.281691</td>\n      <td>5449.201708</td>\n      <td>0.037739</td>\n      <td>0.743992</td>\n      <td>1.501362</td>\n      <td>1.435231</td>\n    </tr>\n    <tr>\n      <th>-1734.705811</th>\n      <th>Mat1.5</th>\n      <th>Per_Arb</th>\n      <th>Mat0.5</th>\n      <td>3030.710125</td>\n      <td>105.029607</td>\n      <td>5973.878408</td>\n      <td>5926.803683</td>\n      <td>0.798240</td>\n      <td>0.027663</td>\n      <td>1.573423</td>\n      <td>1.561024</td>\n    </tr>\n    <tr>\n      <th>-1713.608154</th>\n      <th>Mat0.5</th>\n      <th>Per_Arb</th>\n      <th>RBF</th>\n      <td>127.506101</td>\n      <td>3831.431239</td>\n      <td>4244.671627</td>\n      <td>4398.272332</td>\n      <td>0.033583</td>\n      <td>1.009137</td>\n      <td>1.117978</td>\n      <td>1.158434</td>\n    </tr>\n    <tr>\n      <th>-1398.571167</th>\n      <th>Mat2.5</th>\n      <th>Per_Arb</th>\n      <th>Mat0.5</th>\n      <td>3156.005256</td>\n      <td>96.256447</td>\n      <td>5978.086293</td>\n      <td>5938.732134</td>\n      <td>0.831241</td>\n      <td>0.025352</td>\n      <td>1.574531</td>\n      <td>1.564166</td>\n    </tr>\n    <tr>\n      <th>-1367.811768</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>134.351948</td>\n      <td>4568.363313</td>\n      <td>5968.643105</td>\n      <td>32.884873</td>\n      <td>0.035386</td>\n      <td>1.203233</td>\n      <td>1.572044</td>\n      <td>0.008661</td>\n    </tr>\n    <tr>\n      <th>-1364.527100</th>\n      <th>Mat0.5</th>\n      <th>Per_Arb</th>\n      <th>Mat1.5</th>\n      <td>125.690511</td>\n      <td>2391.950722</td>\n      <td>5148.232692</td>\n      <td>5028.319055</td>\n      <td>0.033105</td>\n      <td>0.630001</td>\n      <td>1.355961</td>\n      <td>1.324378</td>\n    </tr>\n    <tr>\n      <th>-1322.005127</th>\n      <th>Mat0.5</th>\n      <th>Per_Week</th>\n      <th>Mat1.5</th>\n      <td>116.888837</td>\n      <td>5841.851203</td>\n      <td>8903.529136</td>\n      <td>7.274124</td>\n      <td>0.030787</td>\n      <td>1.538649</td>\n      <td>2.345045</td>\n      <td>0.001916</td>\n    </tr>\n    <tr>\n      <th>-1307.643433</th>\n      <th>Mat0.5</th>\n      <th>Per_Week</th>\n      <th>Mat0.5</th>\n      <td>115.490693</td>\n      <td>5011.731922</td>\n      <td>10855.584100</td>\n      <td>9.253740</td>\n      <td>0.030418</td>\n      <td>1.320009</td>\n      <td>2.859185</td>\n      <td>0.002437</td>\n    </tr>\n    <tr>\n      <th>-1298.525146</th>\n      <th>RBF</th>\n      <th>Per_Arb</th>\n      <th>Mat0.5</th>\n      <td>5011.118188</td>\n      <td>121.518015</td>\n      <td>5664.370060</td>\n      <td>5628.218547</td>\n      <td>1.319847</td>\n      <td>0.032006</td>\n      <td>1.491903</td>\n      <td>1.482382</td>\n    </tr>\n    <tr>\n      <th>-1238.739502</th>\n      <th>Mat0.5</th>\n      <th>Per_Week</th>\n      <th>Mat2.5</th>\n      <td>119.586275</td>\n      <td>3895.232499</td>\n      <td>9137.726887</td>\n      <td>6.669795</td>\n      <td>0.031497</td>\n      <td>1.025941</td>\n      <td>2.406729</td>\n      <td>0.001757</td>\n    </tr>\n    <tr>\n      <th>-757.242493</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>487.166801</td>\n      <td>187.401082</td>\n      <td>1592.437050</td>\n      <td>28.933439</td>\n      <td>0.128312</td>\n      <td>0.049358</td>\n      <td>0.419422</td>\n      <td>0.007621</td>\n    </tr>\n    <tr>\n      <th>-707.888000</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>129.431518</td>\n      <td>121.941032</td>\n      <td>683.594912</td>\n      <td>32.162813</td>\n      <td>0.034090</td>\n      <td>0.032117</td>\n      <td>0.180048</td>\n      <td>0.008471</td>\n    </tr>\n    <tr>\n      <th>-516.528564</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>2285.668017</td>\n      <td>186.759314</td>\n      <td>1841.134398</td>\n      <td>30.105351</td>\n      <td>0.602008</td>\n      <td>0.049189</td>\n      <td>0.484925</td>\n      <td>0.007929</td>\n    </tr>\n    <tr>\n      <th>-489.410400</th>\n      <th>Mat2.5</th>\n      <th>Per_Week</th>\n      <th>Mat0.5</th>\n      <td>1796.917545</td>\n      <td>131.287150</td>\n      <td>19718.900031</td>\n      <td>7.240305</td>\n      <td>0.473279</td>\n      <td>0.034579</td>\n      <td>5.193639</td>\n      <td>0.001907</td>\n    </tr>\n    <tr>\n      <th>-402.086670</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>2107.770475</td>\n      <td>168.318785</td>\n      <td>1302.464115</td>\n      <td>28.611561</td>\n      <td>0.555153</td>\n      <td>0.044332</td>\n      <td>0.343048</td>\n      <td>0.007536</td>\n    </tr>\n    <tr>\n      <th>-392.073547</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>Mat0.5</th>\n      <td>4799.144787</td>\n      <td>221.984807</td>\n      <td>753.243117</td>\n      <td>42.885764</td>\n      <td>1.264017</td>\n      <td>0.058467</td>\n      <td>0.198392</td>\n      <td>0.011295</td>\n    </tr>\n    <tr>\n      <th>-322.171631</th>\n      <th>RBF</th>\n      <th>Per_Week</th>\n      <th>Mat0.5</th>\n      <td>6075.714930</td>\n      <td>220.108936</td>\n      <td>15862.187083</td>\n      <td>7.807146</td>\n      <td>1.600245</td>\n      <td>0.057973</td>\n      <td>4.177843</td>\n      <td>0.002056</td>\n    </tr>\n    <tr>\n      <th>-296.835205</th>\n      <th>Mat0.5</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>136.946248</td>\n      <td>60.261670</td>\n      <td>2558.416096</td>\n      <td>18.831912</td>\n      <td>0.036069</td>\n      <td>0.015872</td>\n      <td>0.673845</td>\n      <td>0.004960</td>\n    </tr>\n    <tr>\n      <th>-250.053970</th>\n      <th>Mat1.5</th>\n      <th>Per_Week</th>\n      <th>Mat0.5</th>\n      <td>2254.237419</td>\n      <td>209.177959</td>\n      <td>17015.443607</td>\n      <td>6.006009</td>\n      <td>0.593730</td>\n      <td>0.055094</td>\n      <td>4.481592</td>\n      <td>0.001582</td>\n    </tr>\n    <tr>\n      <th>47.187729</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>5552.480236</td>\n      <td>61.485172</td>\n      <td>859.797272</td>\n      <td>33.225813</td>\n      <td>1.462433</td>\n      <td>0.016194</td>\n      <td>0.226457</td>\n      <td>0.008751</td>\n    </tr>\n    <tr>\n      <th>368.221436</th>\n      <th>Mat2.5</th>\n      <th>Per_Week</th>\n      <th>RBF</th>\n      <td>95.302267</td>\n      <td>3939.503777</td>\n      <td>2648.371465</td>\n      <td>10.173702</td>\n      <td>0.025101</td>\n      <td>1.037601</td>\n      <td>0.697538</td>\n      <td>0.002680</td>\n    </tr>\n    <tr>\n      <th>395.543213</th>\n      <th>Mat2.5</th>\n      <th>Per_Arb</th>\n      <th>RBF</th>\n      <td>95.132886</td>\n      <td>4667.357917</td>\n      <td>5921.794231</td>\n      <td>4690.324543</td>\n      <td>0.025056</td>\n      <td>1.229306</td>\n      <td>1.559705</td>\n      <td>1.235355</td>\n    </tr>\n    <tr>\n      <th>509.828369</th>\n      <th>RBF</th>\n      <th>Per_Week</th>\n      <th>Mat1.5</th>\n      <td>5873.190601</td>\n      <td>43.846995</td>\n      <td>18121.744895</td>\n      <td>9.177903</td>\n      <td>1.546903</td>\n      <td>0.011549</td>\n      <td>4.772974</td>\n      <td>0.002417</td>\n    </tr>\n    <tr>\n      <th>698.042236</th>\n      <th>RBF</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>5176.679932</td>\n      <td>107.474327</td>\n      <td>1362.947994</td>\n      <td>35.528365</td>\n      <td>1.363454</td>\n      <td>0.028307</td>\n      <td>0.358978</td>\n      <td>0.009358</td>\n    </tr>\n    <tr>\n      <th>699.712646</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>104.099146</td>\n      <td>57.131838</td>\n      <td>3054.774322</td>\n      <td>21.847053</td>\n      <td>0.027418</td>\n      <td>0.015048</td>\n      <td>0.804578</td>\n      <td>0.005754</td>\n    </tr>\n    <tr>\n      <th>1037.097900</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>97.761909</td>\n      <td>25.893531</td>\n      <td>684.856723</td>\n      <td>33.527309</td>\n      <td>0.025749</td>\n      <td>0.006820</td>\n      <td>0.180380</td>\n      <td>0.008831</td>\n    </tr>\n    <tr>\n      <th>1056.807861</th>\n      <th>Mat2.5</th>\n      <th>Per_Week</th>\n      <th>Mat2.5</th>\n      <td>95.375363</td>\n      <td>115.516166</td>\n      <td>13417.980194</td>\n      <td>8.431754</td>\n      <td>0.025120</td>\n      <td>0.030425</td>\n      <td>3.534079</td>\n      <td>0.002221</td>\n    </tr>\n    <tr>\n      <th>1119.735596</th>\n      <th>Mat2.5</th>\n      <th>Per_Week</th>\n      <th>Mat1.5</th>\n      <td>96.875436</td>\n      <td>49.950984</td>\n      <td>15140.084670</td>\n      <td>12.916522</td>\n      <td>0.025515</td>\n      <td>0.013156</td>\n      <td>3.987653</td>\n      <td>0.003402</td>\n    </tr>\n    <tr>\n      <th>1129.827026</th>\n      <th>Mat2.5</th>\n      <th>Per_Arb</th>\n      <th>Mat1.5</th>\n      <td>4794.162492</td>\n      <td>38.224954</td>\n      <td>404.703036</td>\n      <td>261.932361</td>\n      <td>1.262705</td>\n      <td>0.010068</td>\n      <td>0.106592</td>\n      <td>0.068989</td>\n    </tr>\n    <tr>\n      <th>1303.167358</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>41.299257</td>\n      <td>126.730206</td>\n      <td>1029.807123</td>\n      <td>24.248696</td>\n      <td>0.010878</td>\n      <td>0.033379</td>\n      <td>0.271235</td>\n      <td>0.006387</td>\n    </tr>\n    <tr>\n      <th>1427.461792</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>Mat1.5</th>\n      <td>43.828261</td>\n      <td>76.758763</td>\n      <td>1241.894807</td>\n      <td>24.910057</td>\n      <td>0.011544</td>\n      <td>0.020217</td>\n      <td>0.327095</td>\n      <td>0.006561</td>\n    </tr>\n    <tr>\n      <th>1500.211792</th>\n      <th>RBF</th>\n      <th>Per_Week</th>\n      <th>Mat2.5</th>\n      <td>7245.301506</td>\n      <td>106.783981</td>\n      <td>18719.544291</td>\n      <td>7.492886</td>\n      <td>1.908295</td>\n      <td>0.028125</td>\n      <td>4.930425</td>\n      <td>0.001974</td>\n    </tr>\n    <tr>\n      <th>1630.341187</th>\n      <th>Mat2.5</th>\n      <th>Per_Month</th>\n      <th>Mat2.5</th>\n      <td>97.883186</td>\n      <td>117.569770</td>\n      <td>1923.247901</td>\n      <td>19.468442</td>\n      <td>0.025781</td>\n      <td>0.030966</td>\n      <td>0.506552</td>\n      <td>0.005128</td>\n    </tr>\n    <tr>\n      <th>1809.703369</th>\n      <th>Mat1.5</th>\n      <th>Per_Week</th>\n      <th>Mat1.5</th>\n      <td>38.362508</td>\n      <td>127.457856</td>\n      <td>11838.071186</td>\n      <td>5.686124</td>\n      <td>0.010104</td>\n      <td>0.033570</td>\n      <td>3.117956</td>\n      <td>0.001498</td>\n    </tr>\n    <tr>\n      <th>1953.407471</th>\n      <th>RBF</th>\n      <th>Per_Arb</th>\n      <th>Mat1.5</th>\n      <td>6690.627841</td>\n      <td>38.207175</td>\n      <td>389.385691</td>\n      <td>280.212866</td>\n      <td>1.762203</td>\n      <td>0.010063</td>\n      <td>0.102558</td>\n      <td>0.073804</td>\n    </tr>\n    <tr>\n      <th>1960.806396</th>\n      <th>Mat1.5</th>\n      <th>Per_Week</th>\n      <th>Mat2.5</th>\n      <td>38.550601</td>\n      <td>123.214993</td>\n      <td>11819.505257</td>\n      <td>9.589931</td>\n      <td>0.010154</td>\n      <td>0.032453</td>\n      <td>3.113066</td>\n      <td>0.002526</td>\n    </tr>\n    <tr>\n      <th>2490.795166</th>\n      <th>Mat1.5</th>\n      <th>Per_Month</th>\n      <th>RBF</th>\n      <td>38.492639</td>\n      <td>90.954760</td>\n      <td>784.138790</td>\n      <td>21.695622</td>\n      <td>0.010138</td>\n      <td>0.023956</td>\n      <td>0.206529</td>\n      <td>0.005714</td>\n    </tr>\n    <tr>\n      <th>2527.500244</th>\n      <th>Mat1.5</th>\n      <th>Per_Arb</th>\n      <th>Mat2.5</th>\n      <td>38.252934</td>\n      <td>1883.964350</td>\n      <td>4400.024826</td>\n      <td>4536.034517</td>\n      <td>0.010075</td>\n      <td>0.496206</td>\n      <td>1.158895</td>\n      <td>1.194718</td>\n    </tr>\n    <tr>\n      <th>2968.091064</th>\n      <th>Mat1.5</th>\n      <th>Per_Arb</th>\n      <th>Mat1.5</th>\n      <td>38.126844</td>\n      <td>1730.256263</td>\n      <td>4853.661272</td>\n      <td>4997.380667</td>\n      <td>0.010042</td>\n      <td>0.455721</td>\n      <td>1.278376</td>\n      <td>1.316229</td>\n    </tr>\n    <tr>\n      <th>3010.300049</th>\n      <th>Mat1.5</th>\n      <th>Per_Arb</th>\n      <th>RBF</th>\n      <td>38.277354</td>\n      <td>3826.049292</td>\n      <td>4257.063095</td>\n      <td>4093.514997</td>\n      <td>0.010082</td>\n      <td>1.007719</td>\n      <td>1.121241</td>\n      <td>1.078166</td>\n    </tr>\n    <tr>\n      <th>4416.419922</th>\n      <th>Mat0.5</th>\n      <th>Per_Week</th>\n      <th>RBF</th>\n      <td>1842.015284</td>\n      <td>4014.698055</td>\n      <td>1805.097394</td>\n      <td>7.280445</td>\n      <td>0.485157</td>\n      <td>1.057406</td>\n      <td>0.475433</td>\n      <td>0.001918</td>\n    </tr>\n    <tr>\n      <th>4672.148926</th>\n      <th>Mat1.5</th>\n      <th>Per_Week</th>\n      <th>RBF</th>\n      <td>535.629953</td>\n      <td>3812.843584</td>\n      <td>1478.579631</td>\n      <td>6.565846</td>\n      <td>0.141076</td>\n      <td>1.004241</td>\n      <td>0.389434</td>\n      <td>0.001729</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_bic_table.groupby(['BIC','add_scale1_K1','scale2_mult_K2', 'scale2_mult_K3']).min(['BIC'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T23:14:53.988746Z",
     "end_time": "2023-04-12T23:14:54.054150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# # Lengthscale for first smoothing kernel\n",
    "# print(bic_save[-1][2].kernels[0].base_kernel.lengthscale.item())\n",
    "# # Lengthscale for second smoothing kernel inside the product\n",
    "# print(bic_save[-1][2].kernels[1].base_kernel.kernels[1].lengthscale.item())\n",
    "# # Lengthscale and Period for periodic kernel inside the product\n",
    "# print(bic_save[-1][2].kernels[1].base_kernel.kernels[0].period_length.item())\n",
    "# print(bic_save[-1][2].kernels[1].base_kernel.kernels[0].lengthscale.item())\n",
    "# print(bic_save[-1][0])\n",
    "# new_bic_save = []\n",
    "# for i in bic_save:\n",
    "#     name = i[0]\n",
    "#     bic = i[1].item()\n",
    "#     s1_ls = i[2].kernels[0].base_kernel.lengthscale.item()\n",
    "#     s2_ls = i[2].kernels[1].base_kernel.kernels[1].lengthscale.item()\n",
    "#     pk_ls = i[2].kernels[1].base_kernel.kernels[0].lengthscale.item()\n",
    "#     pk_pr = i[2].kernels[1].base_kernel.kernels[0].period_length.item()\n",
    "#     new_bic_save.append([name, bic, s1_ls, s2_ls, pk_ls, pk_pr])\n",
    "# new_bic_save_df = pd.DataFrame(\n",
    "#     new_bic_save, columns=['Name', 'BIC', 's1_ls', 's2_ls', 'pk_ls', 'pk_pr'])\n",
    "# new_bic_save_df.to_csv('new_bic_save.csv')\n",
    "# new_bic_save_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:30:32.813400Z",
     "end_time": "2023-04-12T22:30:33.115210Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# # kernel = ScaleKernel(RBFKernel()) + ScaleKernel(MaternKernel()) + ScaleKernel(PeriodicKernel())\n",
    "# kernel = ScaleKernel(RBFKernel() * RBFKernel()) + ScaleKernel(PeriodicKernel() * MaternKernel()) + ScaleKernel(PeriodicKernel() * RBFKernel()) + ScaleKernel(PeriodicKernel() * RBFKernel())\n",
    "# # kernel = ScaleKernel(RBFKernel()) #+ ScaleKernel(MaternKernel()) + ScaleKernel(PeriodicKernel())\n",
    "# kernel = ScaleKernel(MaternKernel(nu=0.5))\n",
    "#\n",
    "#\n",
    "#\n",
    "# results = []\n",
    "# # for i in range(150, 200):\n",
    "# exact_gp = src.utils.TrainTestPlotSaveExactGP(\n",
    "#     ExactGPModel, kernel,\n",
    "#     train_x, train_y, test_x, test_y, num_iter=250,\n",
    "#     name=f'_Mat_RBF')\n",
    "# exact_gp.test_eval_exact_gp()\n",
    "# exact_gp.plot()\n",
    "# bic = exact_gp.get_BIC()\n",
    "# print(bic, kernel)\n",
    "# results.append([bic, kernel])\n",
    "# # del exact_gp\n",
    "# # print(f'BIC: {exact_gp.get_BIC()}')\n",
    "# # print(f'AVG Error: {error}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:30:32.856457Z",
     "end_time": "2023-04-12T22:30:33.115291Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# torch.cuda.mem_get_info(device=None)\n",
    "# exact_gp.plot(set_x_limit=(.992,1))#, set_y_limit=(0,4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:30:32.856491Z",
     "end_time": "2023-04-12T22:30:33.115344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# print(exact_gp.get_BIC())\n",
    "# del exact_gp\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:30:32.856522Z",
     "end_time": "2023-04-12T22:30:33.115404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "## Test all combinations of kernels\n",
    "\n",
    "# for i in k_1:\n",
    "#     for j in k_2:\n",
    "#         for z in k_3:\n",
    "#             kernel = (\n",
    "#                 ScaleKernel(i) +\n",
    "#                 ScaleKernel(j) +\n",
    "#                 ScaleKernel(z))\n",
    "#             exact_gp = src.utils.TrainTestPlotSaveExactGP(\n",
    "#                 ExactGPModel, kernel,\n",
    "#                 train_x, train_y, test_x, test_y,\n",
    "#                 name=f'{str(kernel_dict[i])}{str(kernel_dict[j])}{str(kernel_dict[z])}')\n",
    "#             exact_gp.test_eval_exact_gp()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:30:32.858726Z",
     "end_time": "2023-04-12T22:30:33.115583Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
