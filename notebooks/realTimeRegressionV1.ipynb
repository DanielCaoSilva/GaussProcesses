{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://www.ndbc.noaa.gov/data/realtime2/46268.txt\",delim_whitespace=True)\n",
    "df.info()\n",
    "\n",
    "df.drop(index=df.index[0],\n",
    "        axis=0,\n",
    "        inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['WVHT'] = df['WVHT'].astype(float)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.reindex(index=df.index[::-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.rename(columns={\"#YY\": \"year\",\n",
    "                   \"MM\": \"month\",\n",
    "                   \"DD\": \"day\",\n",
    "                   \"hh\": \"hour\",\n",
    "                   \"mm\": \"minute\"})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['WVHT']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is markdown\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_y = torch.tensor(df['WVHT'].values.astype(np.float32))\n",
    "train_x = torch.linspace(0,1,train_y.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gpytorch.kernels import RBFKernel, CosineKernel, ScaleKernel, PeriodicKernel\n",
    "from custom_kernel import MinKernel, AR2Kernel\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, covar_module):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = covar_module\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kernel_1 = (\n",
    "        ScaleKernel(AR2Kernel()) +\n",
    "        ScaleKernel(MinKernel()) +\n",
    "        ScaleKernel(RBFKernel())\n",
    "        )\n",
    "kernel_2 = (\n",
    "        ScaleKernel(AR2Kernel()) +\n",
    "        ScaleKernel(MinKernel()) +\n",
    "        ScaleKernel(RBFKernel()) +\n",
    "        ScaleKernel(RBFKernel()*PeriodicKernel())\n",
    "        )\n",
    "\n",
    "\n",
    "kernels = [kernel_1, kernel_2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_iter = 150\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the adam optimizer\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "likelihoods = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(train_x, train_y, likelihood, kernel)\n",
    "\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "    optimizer.param_groups[0]['capturable'] = True\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f    noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "        optimizer.step()\n",
    "    models.append(model)\n",
    "    likelihoods.append(likelihood)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import get_BIC\n",
    "\n",
    "for i in range(len(kernels)):\n",
    "    print(get_BIC(models[i], likelihoods[i], train_y, train_x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "likelihood = likelihoods[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0,1.5,1000)\n",
    "    observed_pred = likelihood(model(test_x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize plot\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = observed_pred.confidence_region()\n",
    "# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(test_x.detach().cpu().numpy(),\n",
    "                lower.detach().cpu().numpy(),\n",
    "                upper.detach().cpu().numpy(), alpha=0.3)\n",
    "# Plot training data as black stars\n",
    "ax.scatter(train_x.detach().cpu().numpy(), train_y.detach().cpu().numpy(), s=0.5)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(test_x.detach().cpu().numpy(), observed_pred.mean.detach().cpu().numpy(), 'blue')\n",
    "\n",
    "ax.set_ylim([0, 1.5])\n",
    "#ax.patch.set_facecolor('green')\n",
    "#ax.patch.set_alpha(.1)\n",
    "ax.legend([\"95% Credible Intervals\", \"Observed Data\", \"Posterior Mean\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}