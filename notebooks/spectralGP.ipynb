{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm.notebook\n",
    "import time\n",
    "import DataGrabber\n",
    "import utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('classic')\n",
    "\n",
    "from utils import set_gpytorch_settings\n",
    "#gpytorch.settings.max_cholesky_size\n",
    "set_gpytorch_settings()\n",
    "\n",
    "# Command in terminal to help with memory allocation\n",
    "# set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Kernel Imports\n",
    "from gpytorch.kernels import PeriodicKernel\n",
    "from custom_kernel import MinKernel, AR2Kernel, MaternKernel, LinearKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.constraints import Interval\n",
    "from custom_kernel import noise_lower, noise_upper, noise_init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                time\n",
      "0       1.349049e+09\n",
      "1       1.349051e+09\n",
      "2       1.349053e+09\n",
      "3       1.349055e+09\n",
      "4       1.349057e+09\n",
      "...              ...\n",
      "174808  1.677116e+09\n",
      "174809  1.677117e+09\n",
      "174810  1.677119e+09\n",
      "174811  1.677121e+09\n",
      "174812  1.677128e+09\n",
      "\n",
      "[174813 rows x 1 columns]\n",
      "                time  wind_dir\n",
      "0       1.349049e+09     999.0\n",
      "1       1.349051e+09     999.0\n",
      "2       1.349053e+09     999.0\n",
      "3       1.349055e+09     999.0\n",
      "4       1.349057e+09     999.0\n",
      "...              ...       ...\n",
      "174808  1.677116e+09     999.0\n",
      "174809  1.677117e+09     999.0\n",
      "174810  1.677119e+09     999.0\n",
      "174811  1.677121e+09     999.0\n",
      "174812  1.677128e+09     999.0\n",
      "\n",
      "[174813 rows x 2 columns]\n",
      "                time  wind_dir  wind_spd\n",
      "0       1.349049e+09     999.0      99.0\n",
      "1       1.349051e+09     999.0      99.0\n",
      "2       1.349053e+09     999.0      99.0\n",
      "3       1.349055e+09     999.0      99.0\n",
      "4       1.349057e+09     999.0      99.0\n",
      "...              ...       ...       ...\n",
      "174808  1.677116e+09     999.0      99.0\n",
      "174809  1.677117e+09     999.0      99.0\n",
      "174810  1.677119e+09     999.0      99.0\n",
      "174811  1.677121e+09     999.0      99.0\n",
      "174812  1.677128e+09     999.0      99.0\n",
      "\n",
      "[174813 rows x 3 columns]\n",
      "                time  wind_dir  wind_spd  gust\n",
      "0       1.349049e+09     999.0      99.0  99.0\n",
      "1       1.349051e+09     999.0      99.0  99.0\n",
      "2       1.349053e+09     999.0      99.0  99.0\n",
      "3       1.349055e+09     999.0      99.0  99.0\n",
      "4       1.349057e+09     999.0      99.0  99.0\n",
      "...              ...       ...       ...   ...\n",
      "174808  1.677116e+09     999.0      99.0  99.0\n",
      "174809  1.677117e+09     999.0      99.0  99.0\n",
      "174810  1.677119e+09     999.0      99.0  99.0\n",
      "174811  1.677121e+09     999.0      99.0  99.0\n",
      "174812  1.677128e+09     999.0      99.0  99.0\n",
      "\n",
      "[174813 rows x 4 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1\n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0\n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1\n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0\n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1\n",
      "...              ...       ...       ...   ...          ...\n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1\n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2\n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1\n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9\n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4\n",
      "\n",
      "[174813 rows x 5 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0\n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0\n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0\n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0\n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0\n",
      "...              ...       ...       ...   ...          ...           ...\n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0\n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0\n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0\n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0\n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0\n",
      "\n",
      "[174813 rows x 6 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  \n",
      "0              99.0  \n",
      "1              99.0  \n",
      "2              99.0  \n",
      "3              99.0  \n",
      "4              99.0  \n",
      "...             ...  \n",
      "174808         99.0  \n",
      "174809         99.0  \n",
      "174810         99.0  \n",
      "174811         99.0  \n",
      "174812         99.0  \n",
      "\n",
      "[174813 rows x 7 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  mean_wave_dir  \n",
      "0              99.0          999.0  \n",
      "1              99.0          999.0  \n",
      "2              99.0          999.0  \n",
      "3              99.0          999.0  \n",
      "4              99.0          999.0  \n",
      "...             ...            ...  \n",
      "174808         99.0          999.0  \n",
      "174809         99.0          999.0  \n",
      "174810         99.0          999.0  \n",
      "174811         99.0          999.0  \n",
      "174812         99.0          999.0  \n",
      "\n",
      "[174813 rows x 8 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  mean_wave_dir  air_pressure  \n",
      "0              99.0          999.0        9999.0  \n",
      "1              99.0          999.0        9999.0  \n",
      "2              99.0          999.0        9999.0  \n",
      "3              99.0          999.0        9999.0  \n",
      "4              99.0          999.0        9999.0  \n",
      "...             ...            ...           ...  \n",
      "174808         99.0          999.0        9999.0  \n",
      "174809         99.0          999.0        9999.0  \n",
      "174810         99.0          999.0        9999.0  \n",
      "174811         99.0          999.0        9999.0  \n",
      "174812         99.0          999.0        9999.0  \n",
      "\n",
      "[174813 rows x 9 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  mean_wave_dir  air_pressure  air_temperature  \n",
      "0              99.0          999.0        9999.0            999.0  \n",
      "1              99.0          999.0        9999.0            999.0  \n",
      "2              99.0          999.0        9999.0            999.0  \n",
      "3              99.0          999.0        9999.0            999.0  \n",
      "4              99.0          999.0        9999.0            999.0  \n",
      "...             ...            ...           ...              ...  \n",
      "174808         99.0          999.0        9999.0            999.0  \n",
      "174809         99.0          999.0        9999.0            999.0  \n",
      "174810         99.0          999.0        9999.0            999.0  \n",
      "174811         99.0          999.0        9999.0            999.0  \n",
      "174812         99.0          999.0        9999.0            999.0  \n",
      "\n",
      "[174813 rows x 10 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  mean_wave_dir  air_pressure  air_temperature  \\\n",
      "0              99.0          999.0        9999.0            999.0   \n",
      "1              99.0          999.0        9999.0            999.0   \n",
      "2              99.0          999.0        9999.0            999.0   \n",
      "3              99.0          999.0        9999.0            999.0   \n",
      "4              99.0          999.0        9999.0            999.0   \n",
      "...             ...            ...           ...              ...   \n",
      "174808         99.0          999.0        9999.0            999.0   \n",
      "174809         99.0          999.0        9999.0            999.0   \n",
      "174810         99.0          999.0        9999.0            999.0   \n",
      "174811         99.0          999.0        9999.0            999.0   \n",
      "174812         99.0          999.0        9999.0            999.0   \n",
      "\n",
      "        sea_surface_temperature  \n",
      "0                     21.100000  \n",
      "1                     21.200001  \n",
      "2                     21.500000  \n",
      "3                     21.200001  \n",
      "4                     21.000000  \n",
      "...                         ...  \n",
      "174808                12.800000  \n",
      "174809                12.800000  \n",
      "174810                12.800000  \n",
      "174811                12.800000  \n",
      "174812                12.500000  \n",
      "\n",
      "[174813 rows x 11 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  mean_wave_dir  air_pressure  air_temperature  \\\n",
      "0              99.0          999.0        9999.0            999.0   \n",
      "1              99.0          999.0        9999.0            999.0   \n",
      "2              99.0          999.0        9999.0            999.0   \n",
      "3              99.0          999.0        9999.0            999.0   \n",
      "4              99.0          999.0        9999.0            999.0   \n",
      "...             ...            ...           ...              ...   \n",
      "174808         99.0          999.0        9999.0            999.0   \n",
      "174809         99.0          999.0        9999.0            999.0   \n",
      "174810         99.0          999.0        9999.0            999.0   \n",
      "174811         99.0          999.0        9999.0            999.0   \n",
      "174812         99.0          999.0        9999.0            999.0   \n",
      "\n",
      "        sea_surface_temperature  dewpt_temperature  \n",
      "0                     21.100000              999.0  \n",
      "1                     21.200001              999.0  \n",
      "2                     21.500000              999.0  \n",
      "3                     21.200001              999.0  \n",
      "4                     21.000000              999.0  \n",
      "...                         ...                ...  \n",
      "174808                12.800000              999.0  \n",
      "174809                12.800000              999.0  \n",
      "174810                12.800000              999.0  \n",
      "174811                12.800000              999.0  \n",
      "174812                12.500000              999.0  \n",
      "\n",
      "[174813 rows x 12 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  mean_wave_dir  air_pressure  air_temperature  \\\n",
      "0              99.0          999.0        9999.0            999.0   \n",
      "1              99.0          999.0        9999.0            999.0   \n",
      "2              99.0          999.0        9999.0            999.0   \n",
      "3              99.0          999.0        9999.0            999.0   \n",
      "4              99.0          999.0        9999.0            999.0   \n",
      "...             ...            ...           ...              ...   \n",
      "174808         99.0          999.0        9999.0            999.0   \n",
      "174809         99.0          999.0        9999.0            999.0   \n",
      "174810         99.0          999.0        9999.0            999.0   \n",
      "174811         99.0          999.0        9999.0            999.0   \n",
      "174812         99.0          999.0        9999.0            999.0   \n",
      "\n",
      "        sea_surface_temperature  dewpt_temperature  visibility  \n",
      "0                     21.100000              999.0        99.0  \n",
      "1                     21.200001              999.0        99.0  \n",
      "2                     21.500000              999.0        99.0  \n",
      "3                     21.200001              999.0        99.0  \n",
      "4                     21.000000              999.0        99.0  \n",
      "...                         ...                ...         ...  \n",
      "174808                12.800000              999.0        99.0  \n",
      "174809                12.800000              999.0        99.0  \n",
      "174810                12.800000              999.0        99.0  \n",
      "174811                12.800000              999.0        99.0  \n",
      "174812                12.500000              999.0        99.0  \n",
      "\n",
      "[174813 rows x 13 columns]\n",
      "                time  wind_dir  wind_spd  gust  wave_height  dominant_wpd  \\\n",
      "0       1.349049e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "1       1.349051e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "2       1.349053e+09     999.0      99.0  99.0          1.1          17.0   \n",
      "3       1.349055e+09     999.0      99.0  99.0          1.0          17.0   \n",
      "4       1.349057e+09     999.0      99.0  99.0          1.1          18.0   \n",
      "...              ...       ...       ...   ...          ...           ...   \n",
      "174808  1.677116e+09     999.0      99.0  99.0          3.1           8.0   \n",
      "174809  1.677117e+09     999.0      99.0  99.0          3.2           7.0   \n",
      "174810  1.677119e+09     999.0      99.0  99.0          3.1           7.0   \n",
      "174811  1.677121e+09     999.0      99.0  99.0          2.9           8.0   \n",
      "174812  1.677128e+09     999.0      99.0  99.0          2.4           8.0   \n",
      "\n",
      "        average_wpd  mean_wave_dir  air_pressure  air_temperature  \\\n",
      "0              99.0          999.0        9999.0            999.0   \n",
      "1              99.0          999.0        9999.0            999.0   \n",
      "2              99.0          999.0        9999.0            999.0   \n",
      "3              99.0          999.0        9999.0            999.0   \n",
      "4              99.0          999.0        9999.0            999.0   \n",
      "...             ...            ...           ...              ...   \n",
      "174808         99.0          999.0        9999.0            999.0   \n",
      "174809         99.0          999.0        9999.0            999.0   \n",
      "174810         99.0          999.0        9999.0            999.0   \n",
      "174811         99.0          999.0        9999.0            999.0   \n",
      "174812         99.0          999.0        9999.0            999.0   \n",
      "\n",
      "        sea_surface_temperature  dewpt_temperature  visibility  water_level  \n",
      "0                     21.100000              999.0        99.0         99.0  \n",
      "1                     21.200001              999.0        99.0         99.0  \n",
      "2                     21.500000              999.0        99.0         99.0  \n",
      "3                     21.200001              999.0        99.0         99.0  \n",
      "4                     21.000000              999.0        99.0         99.0  \n",
      "...                         ...                ...         ...          ...  \n",
      "174808                12.800000              999.0        99.0         99.0  \n",
      "174809                12.800000              999.0        99.0         99.0  \n",
      "174810                12.800000              999.0        99.0         99.0  \n",
      "174811                12.800000              999.0        99.0         99.0  \n",
      "174812                12.500000              999.0        99.0         99.0  \n",
      "\n",
      "[174813 rows x 14 columns]\n",
      "['time', 'latitude', 'longitude', 'wind_dir', 'wind_spd', 'gust', 'wave_height', 'dominant_wpd', 'average_wpd', 'mean_wave_dir', 'air_pressure', 'air_temperature', 'sea_surface_temperature', 'dewpt_temperature', 'visibility', 'water_level']\n"
     ]
    }
   ],
   "source": [
    "# Grab Data and create tensors\n",
    "data_grab = DataGrabber.DataGrab(site_number='46221', year='9999', data_type=None) # year=[\"2020\", \"2021\", \"2022\"])\n",
    "wave_data = data_grab.process_buoy_data()\n",
    "print(data_grab.get_vars())\n",
    "# drop_this_max = wave_data.sea_surface_temperature.max()\n",
    "# wave_data = wave_data.loc[wave_data.sea_surface_temperature!=drop_this_max]\n",
    "y = torch.tensor(wave_data['sea_surface_temperature'].values.astype(np.float32)).cuda()\n",
    "X = torch.tensor(wave_data['time'].values.astype(np.float32)).cuda()\n",
    "X = X.reshape(-1,1)\n",
    "# wave_data\n",
    "X\n",
    "X_old = X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\GPs\\lib\\site-packages\\pandas\\compat\\_optional.py:138\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[1;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 138\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GPs\\lib\\importlib\\__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:984\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m wave_data \u001B[38;5;241m=\u001B[39m wave_data\u001B[38;5;241m.\u001B[39mreplace(to_replace \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9999.0\u001B[39m, value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan)\n\u001B[0;32m      4\u001B[0m wave_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msea_surface_temperature\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m wave_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msea_surface_temperature\u001B[39m\u001B[38;5;124m'\u001B[39m]\\\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;241m.\u001B[39mreplace(to_replace \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m999.9\u001B[39m, value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mwave_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_feather\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwave_data.feather\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GPs\\lib\\site-packages\\pandas\\util\\_decorators.py:207\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GPs\\lib\\site-packages\\pandas\\core\\frame.py:2681\u001B[0m, in \u001B[0;36mDataFrame.to_feather\u001B[1;34m(self, path, **kwargs)\u001B[0m\n\u001B[0;32m   2656\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2657\u001B[0m \u001B[38;5;124;03mWrite a DataFrame to the binary Feather format.\u001B[39;00m\n\u001B[0;32m   2658\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2677\u001B[0m \u001B[38;5;124;03msupports custom indices e.g. `to_parquet`.\u001B[39;00m\n\u001B[0;32m   2678\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2679\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeather_format\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_feather\n\u001B[1;32m-> 2681\u001B[0m to_feather(\u001B[38;5;28mself\u001B[39m, path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GPs\\lib\\site-packages\\pandas\\io\\feather_format.py:51\u001B[0m, in \u001B[0;36mto_feather\u001B[1;34m(df, path, storage_options, **kwargs)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;129m@doc\u001B[39m(storage_options\u001B[38;5;241m=\u001B[39m_shared_docs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_feather\u001B[39m(\n\u001B[0;32m     30\u001B[0m     df: DataFrame,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     34\u001B[0m ):\n\u001B[0;32m     35\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;124;03m    Write a DataFrame to the binary Feather format.\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03m        .. versionadded:: 1.1.0\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m     \u001B[43mimport_optional_dependency\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpyarrow\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m feather\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(df, DataFrame):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\GPs\\lib\\site-packages\\pandas\\compat\\_optional.py:141\u001B[0m, in \u001B[0;36mimport_optional_dependency\u001B[1;34m(name, extra, errors, min_version)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 141\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "wave_data = wave_data.replace(to_replace = 999.0, value = np.nan)\n",
    "wave_data = wave_data.replace(to_replace = 99.0, value = np.nan)\n",
    "wave_data = wave_data.replace(to_replace = 9999.0, value = np.nan)\n",
    "wave_data['sea_surface_temperature'] = wave_data['sea_surface_temperature']\\\n",
    "    .replace(to_replace = 999.9, value = np.nan)\n",
    "\n",
    "# wave_data.to_feather('wave_data.feather')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for name in wave_data.columns:\n",
    "#     if name != \"time\":\n",
    "#         wave_data.plot(x='time', y=name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(max(wave_data['sea_surface_temperature']))\n",
    "print(min(wave_data['sea_surface_temperature']))\n",
    "plt.plot(wave_data['time'], wave_data['sea_surface_temperature'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scaler(a, X_old=X_old, center=True):\n",
    "    if center is True:\n",
    "        a = a - X_old.min(0).values\n",
    "    return a / (X_old.max(0).values - X_old.min(0).values)\n",
    "\n",
    "# Standardize Data\n",
    "# print(torch.max(y, 0, keepdim=False))\n",
    "# torch.dr\n",
    "X = (X - X.min(0).values) / (X.max(0).values - X.min(0).values)\n",
    "X = scaler(X, X_old)\n",
    "y = y.log()\n",
    "y = y - torch.min(y)\n",
    "y = 2 * (y / torch.max(y)) - 1  #<--- This gives 0 when the at max y value\n",
    "# Training vs test\n",
    "from math import floor\n",
    "#train_n = int(floor(0.9 * len(X)))\n",
    "# X = preprocessing.normalize(X.cpu())\n",
    "# y = preprocessing.normalize(y.cpu())\n",
    "y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(y.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "series = wave_data['sea_surface_temperature'].diff().diff(48).dropna().iloc[0:100000]\n",
    "#series = wave_data['sea_surface_temperature']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(series)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(series)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "\n",
    "\n",
    "plot_acf(series)\n",
    "plot_pacf(series)\n",
    "\n",
    "#plot_acf(series, lags=1500)\n",
    "#plot_pacf(series, lags=1500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_n = 800\n",
    "train_x = X[test_n:].contiguous().cuda()\n",
    "train_y = y[test_n:].contiguous().cuda()\n",
    "test_x = X[-test_n:].contiguous().cuda()\n",
    "test_y = y[-test_n:].contiguous().cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X.min())\n",
    "print(X.max())\n",
    "print(X.mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_x.min())\n",
    "print(train_x.max())\n",
    "print(train_x.mean())\n",
    "\n",
    "print(test_x.min())\n",
    "print(test_x.max())\n",
    "print(test_x.mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate the train_loader and train_dataset\n",
    "train_loader, train_dataset, test_loader, test_dataset = utils.create_train_loader_and_dataset(\n",
    "    train_x, train_y, test_x, test_y)\n",
    "data_compact = [train_x, train_y, test_x, test_y, train_loader, train_dataset, test_loader, test_dataset]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class StandardApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MeanFieldApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.MeanFieldVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class MAPApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "def make_orthogonal_vs(model, train_x):\n",
    "    mean_inducing_points = torch.randn(1000, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "    covar_inducing_points = torch.randn(100, train_x.size(-1), dtype=train_x.dtype, device=train_x.device)\n",
    "\n",
    "    covar_variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "        model, covar_inducing_points,\n",
    "        gpytorch.variational.CholeskyVariationalDistribution(covar_inducing_points.size(-2)),\n",
    "        learn_inducing_locations=True\n",
    "    )\n",
    "\n",
    "    variational_strategy = gpytorch.variational.OrthogonallyDecoupledVariationalStrategy(\n",
    "        covar_variational_strategy, mean_inducing_points,\n",
    "        gpytorch.variational.DeltaVariationalDistribution(mean_inducing_points.size(-2)),\n",
    "    )\n",
    "    return variational_strategy\n",
    "\n",
    "class OrthDecoupledApproximateGP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = make_orthogonal_vs(self, train_x)\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class SpectralDeltaGP(gpytorch.models.ExactGP):\n",
    "    # def __init__(self, train_x, train_y, kernel, num_deltas, noise_init=None):\n",
    "    #     likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(1e-11))\n",
    "    #     likelihood.register_prior(\"noise_prior\", gpytorch.priors.HorseshoePrior(0.1), \"noise\")\n",
    "    #     likelihood.noise = 1e-2\n",
    "    def __init__(self, inducing_points, kernel):\n",
    "        variational_distribution = gpytorch.variational.DeltaVariationalDistribution(inducing_points)\n",
    "        #variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(inducing_points.size(-2))\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        #super(SpectralDeltaGP, self).__init__(train_x, train_y, likelihood)\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        #base_covar_module = kernel #gpytorch.kernels.SpectralDeltaKernel(num_dims=train_x.size(-1), num_deltas=num_deltas)\n",
    "        #base_covar_module.initialize_from_data(train_x[0], train_y[0])\n",
    "        self.covar_module = kernel#gpytorch.kernels.ScaleKernel(base_covar_module)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "\n",
    "#likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "#model = SpectralMixtureGPModel(train_x, train_y, likelihood)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gpytorch.kernels import SpectralMixtureKernel\n",
    "\n",
    "num_deltas = 300\n",
    "kernel_old = (\n",
    "        #ScaleKernel(AR2Kernel()) +\n",
    "        #ScaleKernel(MinKernel()*RBFKernel()) +\n",
    "        #ScaleKernel(MinKernel())+\n",
    "        #ScaleKernel(RBFKernel()) +\n",
    "        #ScaleKernel(RBFKernel()*LinearKernel())+\n",
    "        ScaleKernel(MaternKernel(nu=0.5)) +\n",
    "        ScaleKernel(MaternKernel(nu=1.5)*PeriodicKernel(period_length_constraint=Interval(\n",
    "            lower_bound=1e-4,\n",
    "            upper_bound=0.1,\n",
    "            initial_value=0.01\n",
    "        ))) +\n",
    "        ScaleKernel(MaternKernel(nu=1.5)*PeriodicKernel(period_length_constraint=Interval(\n",
    "            lower_bound=0.05,\n",
    "            upper_bound=0.3,\n",
    "            initial_value=0.15\n",
    "        ))) +\n",
    "        ScaleKernel(MaternKernel(nu=1.5)*PeriodicKernel(period_length_constraint=Interval(\n",
    "            lower_bound=0.25,\n",
    "            upper_bound=1,\n",
    "            initial_value=0.5\n",
    "        ))) +\n",
    "        ScaleKernel(gpytorch.kernels.SpectralDeltaKernel(\n",
    "            num_dims=train_x.size(-1),\n",
    "            num_deltas=num_deltas,\n",
    "        )) +\n",
    "        ScaleKernel(gpytorch.kernels.SpectralMixtureKernel(num_mixtures=4))\n",
    "        #ScaleKernel(RBFKernel()*PeriodicKernel())\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k4_spectral_base = SpectralMixtureKernel(num_mixtures=4)\n",
    "k4_spectral_base.initialize_from_data_empspect(train_x, train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "k1 = copy.deepcopy(k4_spectral_base)\n",
    "\n",
    "k2 = copy.deepcopy(k4_spectral_base) *PeriodicKernel(\n",
    "    period_length_constraint=Interval(\n",
    "    lower_bound=1/4000,\n",
    "    upper_bound=5/(2*365),\n",
    "    initial_value=1/(365*2))\n",
    ")\n",
    "\n",
    "k3 = ScaleKernel(MaternKernel(nu=1.5)*PeriodicKernel(\n",
    "    period_length_constraint=Interval(\n",
    "    lower_bound=1/4000,\n",
    "    upper_bound=10/(2*365),\n",
    "    initial_value=1/(2*365))\n",
    "))\n",
    "\n",
    "k4 = ScaleKernel(MaternKernel(nu=0.5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler(60*24, center=False)  # minutes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler(60*24*30, center=False)  # minutes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Mat32 = MaternKernel(nu=1.5)\n",
    "\n",
    "# Per_Day = PeriodicKernel(\n",
    "#     period_length_constraint=Interval(\n",
    "#     lower_bound=scaler(60*24, center=False) / 100,\n",
    "#     upper_bound=scaler(60*24, center=False) * 100,\n",
    "#     initial_value=scaler(60*24, center=False))\n",
    "# )\n",
    "\n",
    "Per_Month = PeriodicKernel(\n",
    "    period_length_constraint=Interval(\n",
    "    lower_bound=scaler(60*24*30, center=False) / 100,\n",
    "    upper_bound=scaler(60*24*30, center=False) * 100,\n",
    "    initial_value=scaler(60*24*30, center=False))\n",
    ")\n",
    "\n",
    "# kernel = (\n",
    "# \tk1 + k3 + k4\n",
    "#     # not: ScaleKernel(k1+k2) since they all have spectral component\n",
    "# )\n",
    "\n",
    "kernel = (\n",
    "\tScaleKernel(Mat32) +\n",
    "    # ScaleKernel(Per_Day) +\n",
    "    ScaleKernel(Per_Month)\n",
    "    # not: ScaleKernel(k1+k2) since they all have spectral component\n",
    ")\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint = Interval(noise_lower, noise_upper,initial_value=noise_init))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gpytorch.settings.cholesky_max_tries._set_value(100)\n",
    "# gpytorch.settings.max_cholesky_size._set_value(1000)\n",
    "gpytorch.settings.cholesky_jitter._set_value(double_value=1e8, float_value=1e-4, half_value=1e-3)\n",
    "num_ind_pts = 128 # Number of inducing points (128 is default for train_and_test_approximate_gp function)\n",
    "num_epochs = 15\n",
    "\n",
    "#m1, l1 = utils.train_and_test_approximate_gp(\n",
    "#    StandardApproximateGP, kernel, *data_compact, num_epochs=100, num_ind_pts=num_ind_pts)\n",
    "# m2, l2 = utils.train_and_test_approximate_gp(\n",
    "#     MeanFieldApproximateGP, kernel, *data_compact, num_epochs=100, num_ind_pts=num_ind_pts)\n",
    "# m3, l3 = utils.train_and_test_approximate_gp(\n",
    "#     MAPApproximateGP, kernel, *data_compact, num_epochs=100, num_ind_pts=num_ind_pts)\n",
    "# m4, l4 = utils.train_and_test_approximate_gp(\n",
    "#     OrthDecoupledApproximateGP, kernel, *data_compact, num_epochs=100, num_ind_pts=num_ind_pts)\n",
    "# m5, l5 = utils.train_and_test_approximate_gp(\n",
    "#     SpectralDeltaGP, kernel, *data_compact, num_epochs=100, num_ind_pts=num_deltas)\n",
    "# m6, l6 = utils.train_and_test_approximate_gp(\n",
    "#     SpectralMixtureGPModel, kernel, *data_compact, num_epochs=100, num_ind_pts=num_deltas)\n",
    "#l1 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "#m1 = SpectralMixtureGPModel(train_x, train_y, likelihood)\n",
    "m1, l1 = utils.train_and_test_approximate_gp(\n",
    "    StandardApproximateGP, kernel, *data_compact, num_epochs=num_epochs, num_ind_pts=num_ind_pts)\n",
    "#print(kernel.kernels[2].base_kernel.lengthscale)\n",
    "m2, l2 = utils.train_and_test_approximate_gp(\n",
    "    OrthDecoupledApproximateGP, kernel, *data_compact, num_epochs=num_epochs, num_ind_pts=num_ind_pts)\n",
    "#print(kernel.kernels[2].base_kernel.lengthscale)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(m1.covar_module.kernels[0].outputscale)\n",
    "print(m1.covar_module.kernels[1].outputscale)\n",
    "# print(m1.covar_module.kernels[2].outputscale)\n",
    "\n",
    "\n",
    "print(m2.covar_module.kernels[0].outputscale)\n",
    "print(m2.covar_module.kernels[1].outputscale)\n",
    "# print(m2.covar_module.kernels[2].outputscale)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairs = [[m1, l1],\n",
    "        [m2, l2],]# [m3, l3],\n",
    "#         [m4, l4], [m5, l5],\n",
    "        #[m1, l1]]\n",
    "\n",
    "for pair in pairs:\n",
    "    model = pair[0]\n",
    "    likelihood = pair[1]\n",
    "    model.eval()\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x[:,0].detach().cpu().numpy(),\n",
    "                    lower.detach().cpu().numpy(),\n",
    "                    upper.detach().cpu().numpy(), alpha=0.3)\n",
    "    # Plot training data as black stars\n",
    "    ax.scatter(train_x[:,0].detach().cpu().numpy(), train_y.detach().cpu().numpy(), s=0.5)\n",
    "    #ax.scatter(model.variational_strategy.inducing_points[:,0].detach().cpu().numpy(),\n",
    "    #           np.zeros(500)+1, s=0.5)\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x[:,0].detach().cpu().numpy(), observed_pred.mean.detach().cpu().numpy(), 'blue')\n",
    "    ax.scatter(\n",
    "        test_x[:,0].detach().cpu().numpy(),\n",
    "        test_y.detach().cpu().numpy(),\n",
    "        s=1, color=\"red\")\n",
    "    # ax.set_xlim(.999,1)\n",
    "    ax.set_xlim(0,1)\n",
    "    #ax.set_xlim(0.65,0.75)\n",
    "    ax.vlines(m1.variational_strategy.inducing_points.detach().cpu().numpy(), ymin = -1.6, ymax = -1.5)\n",
    "\n",
    "    #ax.set_ylim([0, 1.5])\n",
    "    #ax.patch.set_facecolor('green')\n",
    "    #ax.patch.set_alpha(.1)\n",
    "    ax.legend([\"95% Credible Intervals\", \"Observed Data\", \"Posterior Mean\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    m1(test_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i in range(len(m1.covar_module.kernels)):\n",
    "#     print(m1.covar_module.kernels[i].outputscale)\n",
    "torch.cuda.memory_summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import get_BIC\n",
    "\n",
    "print(get_BIC(m1, likelihood, train_y, train_x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m1.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(m1(test_x))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize plot\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = observed_pred.confidence_region()\n",
    "# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(test_x.detach().cpu().numpy(),\n",
    "                lower.detach().cpu().numpy(),\n",
    "                upper.detach().cpu().numpy(), alpha=0.3)\n",
    "# Plot training data as black stars\n",
    "ax.scatter(train_x.detach().cpu().numpy(), train_y.detach().cpu().numpy(), s=0.5)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(test_x.detach().cpu().numpy(), observed_pred.mean.detach().cpu().numpy(), 'blue')\n",
    "\n",
    "ax.set_ylim([0, 1.5])\n",
    "#ax.patch.set_facecolor('green')\n",
    "#ax.patch.set_alpha(.1)\n",
    "ax.legend([\"95% Credible Intervals\", \"Observed Data\", \"Posterior Mean\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
