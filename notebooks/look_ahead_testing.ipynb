{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-24T10:20:31.919536908Z",
     "start_time": "2023-05-24T10:20:31.586058126Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libtiff.so.5: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgpytorch\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcopy\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/matplotlib/__init__.py:131\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse \u001B[38;5;28;01mas\u001B[39;00m parse_version\n\u001B[1;32m    129\u001B[0m \u001B[38;5;66;03m# cbook must import matplotlib only within function\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;66;03m# definitions, so it is safe to import from it here.\u001B[39;00m\n\u001B[0;32m--> 131\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sanitize_sequence\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MatplotlibDeprecationWarning\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/matplotlib/rcsetup.py:27\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, cbook\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ls_mapper\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Colormap, is_color_like\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_fontconfig_pattern\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_fontconfig_pattern\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_enums\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m JoinStyle, CapStyle\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/matplotlib/colors.py:51\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumbers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Number\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mPngImagePlugin\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PngInfo\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/PIL/Image.py:103\u001B[0m\n\u001B[1;32m     94\u001B[0m MAX_IMAGE_PIXELS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001B[39;00m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001B[39;00m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;66;03m# import Image and use the Image.core variable instead.\u001B[39;00m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001B[39;00m\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;66;03m# and should be considered private and subject to change.\u001B[39;00m\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _imaging \u001B[38;5;28;01mas\u001B[39;00m core\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m __version__ \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(core, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    106\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    107\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    108\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCore version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mgetattr\u001B[39m(core,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    109\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPillow version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    110\u001B[0m         )\n",
      "\u001B[0;31mImportError\u001B[0m: libtiff.so.5: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.insert(0,Path(os.getcwd()).parent.__str__())\n",
    "# sys.path.append(Path(os.getcwd()).parent.__str__())\n",
    "import torch\n",
    "import gpytorch\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import block_reduce\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import sys \n",
    "# print(sys.path)\n",
    "from src.utils import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('classic')\n",
    "set_gpytorch_settings(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading data file and cleaning missing values\n",
    "df = pd.read_feather('../Data/feather/46221_9999_wave_height.feather')\n",
    "parameters_wave = ['time', 'wave_height']\n",
    "parameters_temp = ['time', 'sea_surface_temperature']\n",
    "df_as_np = df \\\n",
    "    .loc[:, parameters_wave] \\\n",
    "    .astype(float) \\\n",
    "    .replace(to_replace=[999.0, 99.0, 9999.0], value=np.nan) \\\n",
    "    .to_numpy()\n",
    "using_sk = block_reduce(df_as_np, block_size=(24, 1), func=np.mean).astype(float)\n",
    "X = torch.tensor(using_sk[:-1, 0]).float().cuda()\n",
    "y = torch.tensor(using_sk[:-1, 1]).float().cuda()\n",
    "X = X.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "X = X[~torch.any(y.isnan(), dim=1)]\n",
    "y = y[~torch.any(y.isnan(), dim=1)]\n",
    "y = y.flatten()\n",
    "X_old = X\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def scaler(a, X_old=X_old, center=True):\n",
    "    if center is True:\n",
    "        a = a - X_old.min(0).values\n",
    "    return a / (X_old.max(0).values - X_old.min(0).values)\n",
    "\n",
    "\n",
    "def add_new_kernel_term(original_kernel, new_kernel_term, operation):\n",
    "    return str(original_kernel) + str(operation) + str(new_kernel_term)\n",
    "\n",
    "\n",
    "# GP Model Declaration\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "# Scale the time axis and log transform the Y-values\n",
    "X = scaler(X, X_old)\n",
    "y = y.log()\n",
    "\n",
    "# max, min, and scale factor declaration\n",
    "scaler_max = X_old.max(0).values.item()\n",
    "scaler_min = X_old.min(0).values.item()\n",
    "scale_factor = scaler_max - scaler_min\n",
    "scaler_consts = [scaler_max, scaler_min, scale_factor]\n",
    "print(f'Scale Max: {scaler_max}\\n Scale Min: {scaler_min}\\n Scale Factor: {scale_factor}')\n",
    "temp_for_plotting = pd.Series(using_sk[:-1, 0] * 1e9, dtype='datetime64[ns]')\n",
    "plt.plot(temp_for_plotting, using_sk[:-1, 1])\n",
    "plt.xlabel(\"Time (epoch)\")\n",
    "plt.ylabel(\"Significant Wave Height (meters)\")\n",
    "plt.title(f'Significant wave height - after block reducing')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f'Before Block Reduce: {df_as_np.shape}\\n'\n",
    "    f'After Block Reduce: {using_sk.shape}\\n'\n",
    "    f'Number of Nans: {np.count_nonzero(np.isnan(df_as_np))}\\n'\n",
    "    f'Start Time: {datetime.fromtimestamp(df_as_np[0, 0])}\\n'\n",
    "    f'End Time: {datetime.fromtimestamp(df_as_np[-1, 0])}\\n'\n",
    "    f'Number of Days: {df_as_np.shape[0] / 48}\\n'\n",
    "    f'Time Period (Days): {(df_as_np[-1, 0] - df_as_np[0, 0]) / 24 / 60 / 60}')\n",
    "\n",
    "# Prediction range, training and test set define (14, 3, 365)\n",
    "predict_days_out = 28\n",
    "test_n = 2 * predict_days_out\n",
    "train_x = X[test_n:].contiguous().cuda()\n",
    "train_y = y[test_n:].contiguous().cuda()\n",
    "test_x = X[-test_n:].contiguous().cuda()\n",
    "test_y = y[-test_n:].contiguous().cuda()\n",
    "\n",
    "# Generate the train_loader and train_dataset\n",
    "train_loader, train_dataset, test_loader, test_dataset = create_train_loader_and_dataset(\n",
    "    train_x, train_y, test_x, test_y)\n",
    "data_compact = [train_x, train_y, test_x, test_y, train_loader, train_dataset, test_loader, test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data_compact\n",
    "scale = scaler_consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exact_gp_obj = TrainTestPlotSaveExactGP(\n",
    "    ExactGPModel,\n",
    "    kernel=\"RBF+RFF*AR2+Min\",\n",
    "    train_x=data[0], train_y=data[1], test_x=data[2], test_y=data[3],\n",
    "    scaler_min=scale[1], scaler_max=scale[0],\n",
    "    num_iter=1000,\n",
    "    lr=0.01,\n",
    "    name=\"RBF+RFF*AR2+Min\",\n",
    "    save_loss_values=\"save\",\n",
    "    use_scheduler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bic_at_current, hyper_vals = exact_gp_obj.run_train_test_plot_kernel(set_xlim=[0.96, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_total = exact_gp_obj.train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#idx_list = np.random.randint(n_total/2, n_total-6, size = 10000)\n",
    "idx_list = np.random.randint(n_total/2, n_total-6, size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "err_list = []\n",
    "\n",
    "for idx_ahead in idx_list:\n",
    "    print(iter)\n",
    "    with torch.no_grad():\n",
    "        # picks index in the second half of the observed data\n",
    "        print(idx_ahead)\n",
    "\n",
    "        # going to be the new \"training\" set; from t=0 to t=idx_ahead-1\n",
    "        temp_x_train = exact_gp_obj.train_x[:idx_ahead]\n",
    "        temp_y_train = exact_gp_obj.train_y[:idx_ahead]\n",
    "\n",
    "        # this is the new \"testing\" set; t=idx_ahead, ..., idx_ahead+6\n",
    "        temp_x_test = exact_gp_obj.train_x[idx_ahead:(idx_ahead+6)]\n",
    "        temp_y_test = exact_gp_obj.train_y[idx_ahead:(idx_ahead+6)]\n",
    "        exact_gp_obj.trained_model.set_train_data(inputs = temp_x_train, targets = temp_y_train, strict = False)\n",
    "\n",
    "        exact_gp_obj.trained_model.eval()\n",
    "        f = exact_gp_obj.trained_model(temp_x_test)\n",
    "\n",
    "        err = torch.mean((f.mean - temp_y_test).pow(2)).item()\n",
    "\n",
    "        err_list.append(err)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Recommendations:\n",
    "# 1. Add \"step_ahead_errors\" as a method to the exact_gp_obj class.  input: idx_list, output: err_list\n",
    "# 2. Generate idx_list, set seed first.  Then when you want the errors, you can feed it the same idx_list (fairness)\n",
    "# 3. Compare across models, average over the respective err_list and compare\n",
    "# Single out the top 2 models at each round, come up with these values.  Check for consistency with BIC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
